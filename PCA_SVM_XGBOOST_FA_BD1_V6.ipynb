{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCC CBB\n",
    "\n",
    "Desenvolvido por Ricardo e Thyago.\n",
    "\n",
    "#### Objetivo: \n",
    "\n",
    "Aplicação das técnicas de classificação SVM e XGboost junto ao algoritmo bio-inspirado FA.\n",
    "\n",
    "Neste script é aplicado os algoritmos de classificação SVM e XGboost também o modelo estatístico\n",
    "com seu ponderamento feito pelos algoritmos Bio-inspirados.\n",
    "Também é calculado a Média, tempo e desvio-padrão, bem como o Tempo de execução e a Distância euclidiana \n",
    "entre a posição dos melhores agentes para o FA.\n",
    "\n",
    "Fez-se a analise dos parâmetros de aplicação do XGBoost e a técnica foi reaplicada com os paramêtros atualizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import bigml.api\n",
    "import os\n",
    "import pandas as pd\n",
    "from bigml.api import BigML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import plotly.express as px\n",
    "import cufflinks as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\Users\\\\Ricardo\\\\Desktop\\\\ffmpeg-20200206-343ccfc-win64-static\\\\bin\\\\ffmpeg.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import das bibliotecas do XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = BigML('ricardomorellosantos','b34ec3c18161b1da38b0c5e04520224f7544405e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.download_dataset(dataset='dataset/5e356cd41efc9271bf006ea2', filename=os.getcwd()+'\\\\bigml.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de tratamento da base de dados Churn in Telecom's data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_binario(palavra):\n",
    "    if palavra=='Yes' or palavra==True:\n",
    "        return 0\n",
    "    elif palavra=='No' or palavra==False:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descarregaBaseDados():\n",
    "    df_bigml = pd.read_csv(os.getcwd()+'\\\\bigml.csv')\n",
    "    states = df_bigml['State'].value_counts()\n",
    "    df_bigml['Voice mail plan'] = df_bigml['Voice mail plan'].apply(converte_binario)\n",
    "    df_bigml['International plan'] = df_bigml['International plan'].apply(converte_binario)\n",
    "    df_bigml['Churn'] = df_bigml['Churn'].apply(converte_binario)\n",
    "    df_bigml_target = df_bigml['Churn']\n",
    "    df_bigml.drop('Churn', axis=1, inplace=True)\n",
    "    df_bigml_target.head()\n",
    "    print(df_bigml_target.value_counts())\n",
    "    array_estados = []\n",
    "    i = 0\n",
    "    for index, val in states.iteritems():\n",
    "        array_estados.append(index)    \n",
    "        i = 0\n",
    "    for estado in array_estados:\n",
    "        df_bigml['State'] = df_bigml['State'].replace(to_replace=estado, value=i)\n",
    "        i = i+1\n",
    "    return df_bigml, df_bigml_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para Kfold, XGBoost e SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaKFold(x_pca, df_bigml_target):\n",
    "    divisao = 0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_pca, df_bigml_target, test_size=divisao, random_state = 42)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaSVM(X_train, X_test, y_train): \n",
    "    modelSVM = SVC(probability=True, kernel = 'rbf')\n",
    "    modelSVM.fit(X_train, y_train)\n",
    "    predictionsSVM = modelSVM.predict_proba(X_test)\n",
    "\n",
    "    return predictionsSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaXGBoost(X_train, X_test, y_train):\n",
    "    xg_reg = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 10)\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    predictionsXGBoost = xg_reg.predict_proba(X_test)\n",
    "    return predictionsXGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sw(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.__Positions = []\n",
    "        self.__Gbest = []\n",
    "\n",
    "    def _set_Gbest(self, Gbest):\n",
    "        self.__Gbest = Gbest\n",
    "\n",
    "    def _points(self, agents):\n",
    "        self.__Positions.append([list(i) for i in agents])\n",
    "\n",
    "    def get_agents(self):\n",
    "        \"\"\"Returns a history of all agents of the algorithm (return type:\n",
    "        list)\"\"\"\n",
    "\n",
    "        return self.__Positions\n",
    "\n",
    "    def get_Gbest(self):\n",
    "        \"\"\"Return the best position of algorithm (return type: list)\"\"\"\n",
    "\n",
    "        return list(self.__Gbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def animationFA(agents, function, lb, ub,y_test, sr=False):\n",
    "\n",
    "    side = np.linspace(lb, ub, (ub - lb) * 5)\n",
    "    X, Y = np.meshgrid(side, side)\n",
    "    Z = np.array([np.array([function([X[i][j], Y[i][j]], y_test)\n",
    "                            for j in range(len(X))])\n",
    "                  for i in range(len(X[0]))])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12,6))\n",
    "    ax.set_xlabel('SVM')\n",
    "    ax.set_ylabel('XGBoost')\n",
    "    plt.axes(xlim=(lb, ub), ylim=(lb, ub))\n",
    "    plt.pcolormesh(X, Y, Z, shading='flat')\n",
    "    plt.colorbar()\n",
    "    x = np.array([j[0] for j in agents[0]])\n",
    "    y = np.array([j[1] for j in agents[0]])\n",
    "    sc = plt.scatter(x, y, color='black')\n",
    "\n",
    "    plt.title(function.__name__, loc='left')\n",
    "    plt\n",
    "    def an(i):\n",
    "        x = np.array([j[0] for j in agents[i]])\n",
    "        y = np.array([j[1] for j in agents[i]])\n",
    "        sc.set_offsets(list(zip(x, y)))\n",
    "        plt.title('iteration: {}'.format(i), loc='right')\n",
    "    \n",
    "    Writer = animation.writers['ffmpeg']\n",
    "    writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "    ani = matplotlib.animation.FuncAnimation(fig, an, frames=len(agents) - 1)\n",
    "\n",
    "    if sr:\n",
    "        ani.save('im.mp4', writer=writer)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def animation3D(agents, function, lb, ub, y_test, sr=False):\n",
    "\n",
    "    side = np.linspace(lb, ub, 45)\n",
    "    X, Y = np.meshgrid(side, side)\n",
    "    zs = np.array([function([x, y], y_test) for x, y in zip(np.ravel(X), np.ravel(Y))])\n",
    "    Z = zs.reshape(X.shape)\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = Axes3D(fig)\n",
    "    surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='jet',\n",
    "                           linewidth=0, antialiased=False)\n",
    "    ax.set_xlim(lb, ub)\n",
    "    ax.set_ylim(lb, ub)\n",
    "\n",
    "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "    iter = len(agents)\n",
    "    n = len(agents[0])\n",
    "    t = np.array([np.ones(n) * i for i in range(iter)]).flatten()\n",
    "    b = []\n",
    "    [[b.append(agent) for agent in epoch] for epoch in agents]\n",
    "    c = [function(x, y_test) for x in b]\n",
    "    a = np.asarray(b)\n",
    "    df = pd.DataFrame({\"time\": t, \"x\": a[:, 0], \"y\": a[:, 1], \"z\": c})\n",
    "\n",
    "    def update_graph(num):\n",
    "        data = df[df['time'] == num]\n",
    "        graph._offsets3d = (data.x, data.y, data.z)\n",
    "        title.set_text(function.__name__ + \" \" * 45 + 'iteration: {}'.format(\n",
    "            num))\n",
    "\n",
    "    title = ax.set_title(function.__name__ + \" \" * 45 + 'iteration: 0')\n",
    "\n",
    "    data = df[df['time'] == 0]\n",
    "    graph = ax.scatter(data.x, data.y, data.z, color='black')\n",
    "\n",
    "    ani = matplotlib.animation.FuncAnimation(fig, update_graph, iter,\n",
    "                                             interval=50, blit=False)\n",
    "\n",
    "    if sr:\n",
    "\n",
    "        ani.save('result.mp4')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunca_agentes(array):\n",
    "    for line in array:\n",
    "        if line[0] + line[1] > 1:\n",
    "            line[0] = line[0]/2\n",
    "            line[1] = line[1]/2 \n",
    "    return array;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe para o algoritmo Firefly FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "class fa(sw):\n",
    "    \"\"\"\n",
    "    Firefly Algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, n, function, lb, ub, dimension, iteration, y_test, vetor_pbest, vetor_acertos, csi=1, psi=1,\n",
    "                 alpha0=10, alpha1=0.5, norm0=0, norm1=0.1):\n",
    "        \"\"\"\n",
    "        :param n: number of agents\n",
    "        :param function: test function\n",
    "        :param lb: lower limits for plot axes\n",
    "        :param ub: upper limits for plot axes\n",
    "        :param dimension: space dimension\n",
    "        :param iteration: number of iterations\n",
    "        :param csi: mutual attraction (default value is 1)\n",
    "        :param psi: light absorption coefficient of the medium\n",
    "        (default value is 1)\n",
    "        :param alpha0: initial value of the free randomization parameter alpha\n",
    "        (default value is 1)\n",
    "        :param alpha1: final value of the free randomization parameter alpha\n",
    "        (default value is 0.1)\n",
    "        :param norm0: first parameter for a normal (Gaussian) distribution\n",
    "        (default value is 0)\n",
    "        :param norm1: second parameter for a normal (Gaussian) distribution\n",
    "        (default value is 0.1)\n",
    "        \"\"\"\n",
    "\n",
    "        super(fa, self).__init__()\n",
    "\n",
    "        self.__agents = trunca_agentes(np.random.uniform(lb, ub, (n, dimension)))\n",
    "        self._points(self.__agents)\n",
    "        Pbest = self.__agents[np.array([function(x, y_test)\n",
    "                                        for x in self.__agents]).argmax()]\n",
    "        Gbest = Pbest\n",
    "        vetor_pbest.append(Pbest)\n",
    "        vetor_acertos.append(function(Pbest, y_test))\n",
    "        for t in range(iteration):\n",
    "            alpha = alpha1 + (alpha0 - alpha1) * exp(-t)\n",
    "            for i in range(n):\n",
    "                fitness = [function(x, y_test) for x in self.__agents]\n",
    "                for j in range(n):\n",
    "                    if fitness[i] < fitness[j]:\n",
    "                        self.__move(i, j, t, csi, psi, alpha, dimension,\n",
    "                                    norm0, norm1)\n",
    "                    else:\n",
    "                        self.__agents[i] += np.random.normal(norm0, norm1,\n",
    "                                                             dimension)\n",
    "\n",
    "            self.__agents = trunca_agentes(np.clip(self.__agents, lb, ub))\n",
    "            self._points(self.__agents)\n",
    "            \n",
    "            Pbest = self.__agents[\n",
    "                np.array([function(x, y_test) for x in self.__agents]).argmax()]\n",
    "            if function(Pbest, y_test) > function(Gbest, y_test):\n",
    "                Gbest = Pbest\n",
    "            vetor_pbest.append(Gbest)\n",
    "            vetor_acertos.append(function(Gbest, y_test))\n",
    "        self._set_Gbest(Gbest)\n",
    "\n",
    "    def __move(self, i, j, t, csi, psi, alpha, dimension, norm0, norm1):\n",
    "        r = np.linalg.norm(self.__agents[i] - self.__agents[j])\n",
    "        beta = csi / (1 + psi * r ** 2)\n",
    "        self.__agents[i] = self.__agents[j] + beta * (\n",
    "            self.__agents[i] - self.__agents[j]) + alpha * exp(-t) * \\\n",
    "                                                   np.random.normal(norm0,\n",
    "                                                                    norm1,\n",
    "                                                                    dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para a verificaçao de acertos do modelo estatístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_acertos(predicoes, y_test):\n",
    "    qtd_acertos = []\n",
    "    for i in range(predicoes.shape[0]):\n",
    "        if predicoes[i] == y_test[i]:\n",
    "            qtd_acertos.append(1)\n",
    "        else:\n",
    "            qtd_acertos.append(0)\n",
    "    return np.asarray(qtd_acertos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retorna_acertos(x, y_test):\n",
    "    svm_alpha = ( ( 1 - predictionsSVM[:,1] ) ** x[0] )\n",
    "    xgboost_beta =  ( ( 1 - predictionsXGBoost[:,1] ) ** x[1] )\n",
    "    predicoes = 1 - (svm_alpha*xgboost_beta)\n",
    "    qtd_acertos = np.subtract(y_test,np.round(predicoes))\n",
    "    return np.count_nonzero(qtd_acertos == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação do XGBoost e SVM junto ao algoritmo Firefly FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import SwarmPackagePy\n",
    "import matplotlib.pyplot as plt\n",
    "from SwarmPackagePy import testFunctions as tf\n",
    "\n",
    "df_bigml, df_bigml_target = descarregaBaseDados()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_bigml)\n",
    "\n",
    "scaled_data = scaler.transform(df_bigml)  \n",
    "pca_svm = PCA(n_components = 16)\n",
    "pca_svm.fit(scaled_data)\n",
    "x_pca_svm = pca_svm.transform(scaled_data)\n",
    "\n",
    "pca_xgboost = PCA(n_components=17)\n",
    "pca_xgboost.fit(scaled_data)\n",
    "x_pca_xgboost = pca_xgboost.transform(scaled_data)\n",
    "\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFold(x_pca_svm, df_bigml_target)\n",
    "X_train_xgboost, X_test_xgboost, y_train_xgboost, y_test_xgboost = aplicaKFold(x_pca_xgboost, df_bigml_target)\n",
    "\n",
    "predictionsSVM = aplicaSVM(X_train_svm, X_test_svm, y_train_svm)\n",
    "predictionsXGBoost = aplicaXGBoost(X_train_xgboost, X_test_xgboost, y_train_xgboost)\n",
    "\n",
    "vetor_pbest = []\n",
    "vetor_acertos = []\n",
    "\n",
    "alh = fa(40, retorna_acertos, 0, 1, 2, 50, y_test_svm, vetor_pbest, vetor_acertos)\n",
    "arr = np.array(alh.get_agents())\n",
    "animationFA(alh.get_agents(), retorna_acertos, 0, 1, y_test_svm, sr=True)\n",
    "animation3D(alh.get_agents(), retorna_acertos, 0, 1, y_test_svm, sr=True)\n",
    "print(alh.get_Gbest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APlicação do Modelo Estatístico com o ponderamento dos melhores agentes encontrados na sa´da do algoritmos FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_alpha = ( ( 1 - predictionsSVM[:,1] ) ** alh.get_Gbest()[0] )\n",
    "xgboost_beta =  ( ( 1 - predictionsXGBoost[:,1] ) ** alh.get_Gbest()[1])\n",
    "predicoes = 1 - (svm_alpha*xgboost_beta)\n",
    "qtd_acertos = np.subtract(y_test_svm,np.round(predicoes))\n",
    "np.count_nonzero(qtd_acertos == 0)/len(y_test_svm) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "fpr, tpr, thresholds = roc_curve(y_test_svm, predicoes)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.xlabel('1-Especificidade')\n",
    "plt.ylabel('Sensibilidade')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.title('Curva ROC Modelo estatístico')\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "fig.savefig('ROC_Modelo_Estatistico_BIGML_SVM.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor_acertos\n",
    "assertividade = [(x / 667) * 100 for x in vetor_acertos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acertos = pd.DataFrame(assertividade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "sns.lineplot(data=df_acertos)\n",
    "plt.legend('')\n",
    "plt.title('Porcentagem de acertos FA')\n",
    "plt.xlabel('Iteração')\n",
    "plt.ylabel('Porcentagem')\n",
    "plt.savefig('bigml_fa_porcentagem_acertos.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pbest = pd.DataFrame(vetor_pbest, columns = ['x', 'y'])\n",
    "df_pbest['iteracao'] = np.arange(0, 51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Média, tempo e desvio-padrão FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SwarmPackagePy\n",
    "import matplotlib.pyplot as plt\n",
    "from SwarmPackagePy import testFunctions as tf\n",
    "\n",
    "\n",
    "df_bigml, df_bigml_target = descarregaBaseDados()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_bigml)\n",
    "\n",
    "tempo = []\n",
    "melhor = []\n",
    "\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    t1_start = perf_counter()  \n",
    "    scaled_data = scaler.transform(df_bigml)  \n",
    "    pca_svm = PCA(n_components = 16)\n",
    "    pca_svm.fit(scaled_data)\n",
    "    x_pca_svm = pca_svm.transform(scaled_data)\n",
    "\n",
    "    pca_xgboost = PCA(n_components=17)\n",
    "    pca_xgboost.fit(scaled_data)\n",
    "    x_pca_xgboost = pca_xgboost.transform(scaled_data)\n",
    "\n",
    "    X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFold(x_pca_svm, df_bigml_target)\n",
    "    X_train_xgboost, X_test_xgboost, y_train_xgboost, y_test_xgboost = aplicaKFold(x_pca_xgboost, df_bigml_target)\n",
    "\n",
    "    predictionsSVM = aplicaSVM(X_train_svm, X_test_svm, y_train_svm)\n",
    "    predictionsXGBoost = aplicaXGBoost(X_train_xgboost, X_test_xgboost, y_train_xgboost)\n",
    "\n",
    "    vetor_pbest = []\n",
    "    vetor_acertos = []\n",
    "\n",
    "    alh = fa(40, retorna_acertos, 0, 1, 2, 50, y_test_svm, vetor_pbest, vetor_acertos)\n",
    "    arr = np.array(alh.get_agents())\n",
    "    t1_stop = perf_counter() \n",
    "    melhor.append(alh.get_Gbest())\n",
    "    tempo.append(t1_stop-t1_start)\n",
    "    #animationFA(alh.get_agents(), retorna_acertos, 0, 1, y_test_svm, sr=True)\n",
    "    #animation3D(alh.get_agents(), retorna_acertos, 0, 1, y_test_svm, sr=True)\n",
    "    print(alh.get_Gbest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_fa = pd.DataFrame()\n",
    "df_media_desvpad_fa['tempo'] = tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_fa['solucoes'] = melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_fa = []\n",
    "for solucao in melhor:\n",
    "    svm_alpha = ( ( 1 - predictionsSVM[:,1] ) ** solucao[0] )\n",
    "    xgboost_beta =  ( ( 1 - predictionsXGBoost[:,1] ) ** solucao[1])\n",
    "    predicoes = 1 - (svm_alpha*xgboost_beta)\n",
    "    qtd_acertos = np.subtract(y_test_svm,np.round(predicoes))\n",
    "    np.count_nonzero(qtd_acertos == 0)/len(y_test_svm) * 100\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_svm, predicoes)\n",
    "    auc_fa.append(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_fa['aucs'] = auc_fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_fa[['solucao_x','solucao_y']] = pd.DataFrame(df_media_desvpad_fa.solucoes.values.tolist(), index= df_media_desvpad_fa.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.title('Tempo de execução do algoritmo FA com random_state estático')\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('Tempo (s)')\n",
    "df_media_desvpad_fa['tempo'].plot(yerr=df_media_desvpad_fa['tempo'].std(), marker = 'o')\n",
    "plt.savefig('tempo_execucao_fa_bigml_estatico.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da distância Euclidiana entre as posições dos melhores agentes encontrados no FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "distancias_euclidianas = []\n",
    "cont = 0\n",
    "for i in df_media_desvpad_fa['solucoes']:\n",
    "    if cont < len(df_media_desvpad_fa['solucoes']) - 1:\n",
    "        proximo = df_media_desvpad_fa['solucoes'][cont+1]\n",
    "        primeiro_ponto = (i[0], i[1])\n",
    "        segundo_ponto = (proximo[0], proximo[1])\n",
    "        distancias_euclidianas.append(distance.euclidean(primeiro_ponto, segundo_ponto))\n",
    "        cont = cont+1\n",
    "    else:\n",
    "        distancias_euclidianas.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_fa['distancias_euclidianas'] = distancias_euclidianas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.title('Distância euclidiana entre a posição dos melhores agentes com random_state estático')\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('Distância euclidiana')\n",
    "df_media_desvpad_fa['distancias_euclidianas'].plot(yerr=df_media_desvpad_fa['distancias_euclidianas'].std(), marker = 'o', color='red')\n",
    "plt.savefig('distancia_euclidiana_fa_bigml_estatico.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUCs nas iterações do algoritmo FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.title('AUCs nas execuções com random_state estático')\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('AUC')\n",
    "df_media_desvpad_fa['aucs'] = df_media_desvpad_fa['aucs']\n",
    "print(df_media_desvpad_fa['aucs'].std())\n",
    "df_media_desvpad_fa['aucs'].plot(yerr=df_media_desvpad_fa['aucs'].std(), marker = 'o', color='green')\n",
    "plt.savefig('auc_fa_bigml_estatico.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Média, tempo e desvio-padrão FA com diferentes amostras da base até a convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaKFoldRand(x_pca, df_bigml_target, rand):\n",
    "    divisao = 0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_pca, df_bigml_target, test_size=divisao, random_state = rand)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SwarmPackagePy\n",
    "import matplotlib.pyplot as plt\n",
    "from SwarmPackagePy import testFunctions as tf\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "df_bigml, df_bigml_target = descarregaBaseDados()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_bigml)\n",
    "\n",
    "tempo_rand = []\n",
    "melhor_rand = []\n",
    "rands = []\n",
    "auc_fa = []\n",
    "auc_svm = []\n",
    "auc_xgboost = []\n",
    "convergencia = False\n",
    "media_aucs = 0\n",
    "auc_anterior = 0\n",
    "total_iguais = 0\n",
    "i = 0\n",
    "while(not convergencia):\n",
    "    print(i)\n",
    "    rand = np.random.randint(0, 1000)\n",
    "    t1_start = perf_counter()  \n",
    "    scaled_data = scaler.transform(df_bigml)  \n",
    "    pca_svm = PCA(n_components = 16)\n",
    "    pca_svm.fit(scaled_data)\n",
    "    x_pca_svm = pca_svm.transform(scaled_data)\n",
    "\n",
    "    pca_xgboost = PCA(n_components=17)\n",
    "    pca_xgboost.fit(scaled_data)\n",
    "    x_pca_xgboost = pca_xgboost.transform(scaled_data)\n",
    "    rands.append(rand)\n",
    "    X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFoldRand(x_pca_svm, df_bigml_target, rand)\n",
    "    X_train_xgboost, X_test_xgboost, y_train_xgboost, y_test_xgboost = aplicaKFoldRand(x_pca_xgboost, df_bigml_target, rand)\n",
    "    \n",
    "    predictionsSVM = aplicaSVM(X_train_svm, X_test_svm, y_train_svm)\n",
    "    predictionsXGBoost = aplicaXGBoost(X_train_xgboost, X_test_xgboost, y_train_xgboost)\n",
    "    \n",
    "    fprs, tprs, thresholdss = roc_curve(y_test_svm, predictionsSVM[:,1])\n",
    "    fprx, tprx, thresholdsx = roc_curve(y_test_svm, predictionsXGBoost[:,1])\n",
    "    \n",
    "    auc_svm.append(auc(fprs, tprs))\n",
    "    auc_xgboost.append(auc(fprx, tprx))\n",
    "    \n",
    "    vetor_pbest = []\n",
    "    vetor_acertos = []\n",
    "\n",
    "    alh = fa(40, retorna_acertos, 0, 1, 2, 50, y_test_svm, vetor_pbest, vetor_acertos)\n",
    "    solucao = alh.get_Gbest()\n",
    "    svm_alpha = ( ( 1 - predictionsSVM[:,1] ) ** solucao[0] )\n",
    "    xgboost_beta =  ( ( 1 - predictionsXGBoost[:,1] ) ** solucao[1])\n",
    "    predicoes = 1 - (svm_alpha*xgboost_beta)\n",
    "    qtd_acertos = np.subtract(y_test_svm,np.round(predicoes))\n",
    "    np.count_nonzero(qtd_acertos == 0)/len(y_test_svm) * 100\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_svm, predicoes)\n",
    "    auc_fa.append(auc(fpr, tpr))\n",
    "    \n",
    "    media_aucs = round(sum(auc_fa)/len(auc_fa), 2)\n",
    "    if media_aucs == auc_anterior:\n",
    "        total_iguais = total_iguais + 1\n",
    "    else:\n",
    "        total_iguais = 0\n",
    "    \n",
    "    if total_iguais == 10:\n",
    "        convergencia = True\n",
    "    \n",
    "    print('media_aucs:{}'.format(media_aucs))\n",
    "    auc_anterior = media_aucs\n",
    "    \n",
    "    arr = np.array(alh.get_agents())\n",
    "    t1_stop = perf_counter() \n",
    "    melhor_rand.append(alh.get_Gbest())\n",
    "    tempo_rand.append(t1_stop-t1_start)\n",
    "    \n",
    "    print(alh.get_Gbest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_fa_rand = pd.DataFrame()\n",
    "df_media_desvpad_fa_rand['tempo'] = tempo_rand\n",
    "df_media_desvpad_fa_rand['solucoes'] = melhor_rand\n",
    "df_media_desvpad_fa_rand['rand_values'] = rands\n",
    "df_media_desvpad_fa_rand['aucs'] = auc_fa\n",
    "df_media_desvpad_fa_rand['auc_svm'] = auc_svm\n",
    "df_media_desvpad_fa_rand['auc_xgboost'] = auc_xgboost\n",
    "df_media_desvpad_fa_rand[['solucao_x','solucao_y']] = pd.DataFrame(df_media_desvpad_fa_rand.solucoes.values.tolist(), index= df_media_desvpad_fa_rand.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_media_desvpad_fa_rand['tempo'].std())\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.title('Tempo de execução até convergência da média')\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('Tempo (s)')\n",
    "df_media_desvpad_fa_rand['tempo'].plot(yerr=df_media_desvpad_fa_rand['tempo'].std(), marker = 'o')\n",
    "plt.savefig('tempo_execucao_fa_bigml.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "distancias_euclidianas = []\n",
    "cont = 0\n",
    "for i in df_media_desvpad_fa_rand['solucoes']:\n",
    "    if cont < len(df_media_desvpad_fa_rand['solucoes']) - 1:\n",
    "        proximo = df_media_desvpad_fa_rand['solucoes'][cont+1]\n",
    "        primeiro_ponto = (i[0], i[1])\n",
    "        segundo_ponto = (proximo[0], proximo[1])\n",
    "        distancias_euclidianas.append(distance.euclidean(primeiro_ponto, segundo_ponto))\n",
    "        cont = cont+1\n",
    "    else:\n",
    "        distancias_euclidianas.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_fa_rand['distancias_euclidianas'] = distancias_euclidianas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_fa_rand['distancias_euclidianas'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_fa_rand['AUCs modelo estatístico'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.title('Distância euclidiana entre os melhores agentes até convergência da média')\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('Distância euclidiana')\n",
    "df_media_desvpad_fa_rand['distancias_euclidianas'] = np.clip(df_media_desvpad_fa_rand['distancias_euclidianas'],0, 1)\n",
    "df_media_desvpad_fa_rand['distancias_euclidianas'].plot(yerr=df_media_desvpad_fa_rand['distancias_euclidianas'].std(), marker = 'o', color='red')\n",
    "plt.savefig('distancia_euclidiana_fa_bigml.png')\n",
    "print(df_media_desvpad_fa_rand['distancias_euclidianas'].std())\n",
    "print(df_media_desvpad_fa_rand['distancias_euclidianas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# create valid markers from mpl.markers\n",
    "valid_markers = ([item[0] for item in mpl.markers.MarkerStyle.markers.items() if\n",
    "item[1] is not 'nothing' and not item[1].startswith('tick') and not item[1].startswith('caret')])\n",
    "df_media_desvpad_fa_rand.rename(columns = {'aucs':'AUCs modelo estatístico', 'auc_svm':'AUCs SVM', 'auc_xgboost' : 'AUCs XGBoost'}, inplace = True) \n",
    "\n",
    "ax = df_media_desvpad_fa_rand[['AUCs modelo estatístico', 'AUCs SVM', 'AUCs XGBoost']].plot(figsize=(16,10))\n",
    "\n",
    "\n",
    "# valid_markers = mpl.markers.MarkerStyle.filled_markers\n",
    "markers = np.random.choice(valid_markers, df_media_desvpad_fa_rand.shape[1], replace=False)\n",
    "for i, line in enumerate(ax.get_lines()):\n",
    "    line.set_marker(markers[i])\n",
    "\n",
    "plt.title('AUCs nas execuções até convergência da média')\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "\n",
    "plt.savefig('auc_fa_bigml.png')\n",
    "\n",
    "print(df_media_desvpad_fa_rand['AUCs modelo estatístico'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicações do algoritmo bio-inspirado PSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class swa(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.__Positions = []\n",
    "        self.__Gbest = []\n",
    "\n",
    "    def _set_Gbest(self, __Gbest):\n",
    "        self.__Gbest = __Gbest\n",
    "\n",
    "    def _points(self, agents):\n",
    "        self.__Positions.append([list(i) for i in agents])\n",
    "\n",
    "    def get_agents(self):\n",
    "        \"\"\"Returns a history of all agents of the algorithm (return type:\n",
    "        list)\"\"\"\n",
    "\n",
    "        return self.__Positions\n",
    "\n",
    "    def get_Gbest(self):\n",
    "        \"\"\"Return the best position of algorithm (return type: list)\"\"\"\n",
    "\n",
    "        return list(self.__Gbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class pso(swa):\n",
    "    \"\"\"\n",
    "    Particle Swarm Optimization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, function, lb, ub, dimension, iteration, y_test_svm,vetor_pbest, vetor_acertos, w=0.5, c1=1,\n",
    "                 c2=1):\n",
    "        \"\"\"\n",
    "        :param n: number of agents\n",
    "        :param function: test function\n",
    "        :param lb: lower limits for plot axes\n",
    "        :param ub: upper limits for plot azes\n",
    "        :param dimension: space dimension\n",
    "        :param iteration: the number of iterations\n",
    "        :param w: balance between the range of research and consideration for\n",
    "        suboptimal decisions found (default value is 0.5):\n",
    "        w>1 the particle velocity increases, they fly apart and inspect\n",
    "         the space more carefully;\n",
    "        w<1 particle velocity decreases, convergence speed depends\n",
    "        on parameters c1 and c2 ;\n",
    "        :param c1: ratio between \"cognitive\" and \"social\" component\n",
    "        (default value is 1)\n",
    "        :param c2: ratio between \"cognitive\" and \"social\" component\n",
    "        (default value is 1)\n",
    "        \"\"\"\n",
    "\n",
    "        super(pso, self).__init__()\n",
    "\n",
    "        self.__agents = trunca_agentes(np.random.uniform(lb, ub, (n, dimension)))\n",
    "        velocity = np.zeros((n, dimension))\n",
    "        self._points(self.__agents)\n",
    "\n",
    "        Pbest = self.__agents[np.array([function(x, y_test_svm)\n",
    "                                        for x in self.__agents]).argmax()]\n",
    "        Gbest = Pbest\n",
    "        vetor_pbest.append(Pbest)\n",
    "        vetor_acertos.append(function(Pbest, y_test_svm))\n",
    "        \n",
    "        for t in range(iteration):\n",
    "            r1 = np.random.random((n, dimension))\n",
    "            r2 = np.random.random((n, dimension))\n",
    "            velocity = w * velocity + c1 * r1 * (\n",
    "                Pbest - self.__agents) + c2 * r2 * (\n",
    "                Gbest - self.__agents)\n",
    "            self.__agents += velocity\n",
    "            self.__agents = trunca_agentes(np.clip(self.__agents, lb, ub))\n",
    "            self._points(self.__agents)\n",
    "         \n",
    "            Pbest = self.__agents[\n",
    "                np.array([function(x, y_test_svm) for x in self.__agents]).argmax()]\n",
    "            if function(Pbest, y_test_svm) > function(Gbest, y_test_svm):\n",
    "                Gbest = Pbest\n",
    "            vetor_pbest.append(Pbest)\n",
    "            vetor_acertos.append(function(Pbest, y_test_svm))\n",
    "        \n",
    "        self._set_Gbest(Gbest)\n",
    "        print(Gbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação dos algoritmos XGBoost e SVM junto ao algoritmos PSO até sua convergência "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SwarmPackagePy\n",
    "import matplotlib.pyplot as plt\n",
    "from SwarmPackagePy import testFunctions as tf\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "df_bigml, df_bigml_target = descarregaBaseDados()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_bigml)\n",
    "\n",
    "tempo_rand = []\n",
    "melhor_rand = []\n",
    "rands = []\n",
    "auc_fa = []\n",
    "auc_svm = []\n",
    "auc_xgboost = []\n",
    "convergencia = False\n",
    "media_aucs = 0\n",
    "auc_anterior = 0\n",
    "total_iguais = 0\n",
    "i = 0\n",
    "while(not convergencia):\n",
    "    print(i)\n",
    "    rand = np.random.randint(0, 1000)\n",
    "    t1_start = perf_counter()  \n",
    "    scaled_data = scaler.transform(df_bigml)  \n",
    "    pca_svm = PCA(n_components = 16)\n",
    "    pca_svm.fit(scaled_data)\n",
    "    x_pca_svm = pca_svm.transform(scaled_data)\n",
    "\n",
    "    pca_xgboost = PCA(n_components=17)\n",
    "    pca_xgboost.fit(scaled_data)\n",
    "    x_pca_xgboost = pca_xgboost.transform(scaled_data)\n",
    "    rands.append(rand)\n",
    "    X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFoldRand(x_pca_svm, df_bigml_target, rand)\n",
    "    X_train_xgboost, X_test_xgboost, y_train_xgboost, y_test_xgboost = aplicaKFoldRand(x_pca_xgboost, df_bigml_target, rand)\n",
    "    \n",
    "    predictionsSVM = aplicaSVM(X_train_svm, X_test_svm, y_train_svm)\n",
    "    predictionsXGBoost = aplicaXGBoost(X_train_xgboost, X_test_xgboost, y_train_xgboost)\n",
    "    \n",
    "    fprs, tprs, thresholdss = roc_curve(y_test_svm, predictionsSVM[:,1])\n",
    "    fprx, tprx, thresholdsx = roc_curve(y_test_svm, predictionsXGBoost[:,1])\n",
    "    \n",
    "    auc_svm.append(auc(fprs, tprs))\n",
    "    auc_xgboost.append(auc(fprx, tprx))\n",
    "    \n",
    "    vetor_pbest = []\n",
    "    vetor_acertos = []\n",
    "\n",
    "    alh = pso(40, retorna_acertos, 0, 1, 2, 50, y_test_svm, vetor_pbest, vetor_acertos)\n",
    "    solucao = alh.get_Gbest()\n",
    "    svm_alpha = ( ( 1 - predictionsSVM[:,1] ) ** solucao[0] )\n",
    "    xgboost_beta =  ( ( 1 - predictionsXGBoost[:,1] ) ** solucao[1])\n",
    "    predicoes = 1 - (svm_alpha*xgboost_beta)\n",
    "    qtd_acertos = np.subtract(y_test_svm,np.round(predicoes))\n",
    "    np.count_nonzero(qtd_acertos == 0)/len(y_test_svm) * 100\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_svm, predicoes)\n",
    "    auc_fa.append(auc(fpr, tpr))\n",
    "    \n",
    "    media_aucs = round(sum(auc_fa)/len(auc_fa), 2)\n",
    "    if media_aucs == auc_anterior:\n",
    "        total_iguais = total_iguais + 1\n",
    "    else:\n",
    "        total_iguais = 0\n",
    "    \n",
    "    if total_iguais == 10:\n",
    "        convergencia = True\n",
    "    \n",
    "    print('media_aucs:{}'.format(media_aucs))\n",
    "    auc_anterior = media_aucs\n",
    "    \n",
    "    arr = np.array(alh.get_agents())\n",
    "    t1_stop = perf_counter() \n",
    "    melhor_rand.append(alh.get_Gbest())\n",
    "    tempo_rand.append(t1_stop-t1_start)\n",
    "    \n",
    "    print(alh.get_Gbest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Média, desvio padrão para o PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand = pd.DataFrame()\n",
    "df_media_desvpad_PSO_rand['tempo'] = tempo_rand\n",
    "df_media_desvpad_PSO_rand['solucoes'] = melhor_rand\n",
    "df_media_desvpad_PSO_rand['rand_values'] = rands\n",
    "df_media_desvpad_PSO_rand['aucs'] = auc_fa\n",
    "df_media_desvpad_PSO_rand['auc_svm'] = auc_svm\n",
    "df_media_desvpad_PSO_rand['auc_xgboost'] = auc_xgboost\n",
    "df_media_desvpad_PSO_rand[['solucao_x','solucao_y']] = pd.DataFrame(df_media_desvpad_PSO_rand.solucoes.values.tolist(), index= df_media_desvpad_PSO_rand.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico do tempo de execução do PSO até sua convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_media_desvpad_PSO_rand['tempo'].std())\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.title('Tempo de execução até convergência da média')\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('Tempo (s)')\n",
    "df_media_desvpad_PSO_rand['tempo'].plot(yerr=df_media_desvpad_PSO_rand['tempo'].std(), marker = 'o')\n",
    "plt.savefig('tempo_execucao_pso_bigml.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da distância euclidiana dos melhores agentes para o PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "distancias_euclidianas = []\n",
    "cont = 0\n",
    "for i in df_media_desvpad_fa_rand['solucoes']:\n",
    "    if cont < len(df_media_desvpad_fa_rand['solucoes']) - 1:\n",
    "        proximo = df_media_desvpad_fa_rand['solucoes'][cont+1]\n",
    "        primeiro_ponto = (i[0], i[1])\n",
    "        segundo_ponto = (proximo[0], proximo[1])\n",
    "        distancias_euclidianas.append(distance.euclidean(primeiro_ponto, segundo_ponto))\n",
    "        cont = cont+1\n",
    "    else:\n",
    "        distancias_euclidianas.append(0)\n",
    "df_media_desvpad_fa_rand['distancias_euclidianas'] = distancias_euclidianas\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.title('Distância euclidiana entre os melhores agentes até convergência da média')\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('Distância euclidiana')\n",
    "df_media_desvpad_fa_rand['distancias_euclidianas'] = np.clip(df_media_desvpad_fa_rand['distancias_euclidianas'],0, 1)\n",
    "df_media_desvpad_fa_rand['distancias_euclidianas'].plot(yerr=df_media_desvpad_fa_rand['distancias_euclidianas'].std(), marker = 'o', color='red')\n",
    "plt.savefig('distancia_euclidiana_pso_bigml.png')\n",
    "\n",
    "print(df_media_desvpad_fa_rand['distancias_euclidianas'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico das AUCs em cada execução do PSO até sua convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# create valid markers from mpl.markers\n",
    "valid_markers = ([item[0] for item in mpl.markers.MarkerStyle.markers.items() if\n",
    "item[1] is not 'nothing' and not item[1].startswith('tick') and not item[1].startswith('caret')])\n",
    "df_media_desvpad_fa_rand.rename(columns = {'aucs':'AUCs modelo estatístico', 'auc_svm':'AUCs SVM', 'auc_xgboost' : 'AUCs XGBoost'}, inplace = True) \n",
    "\n",
    "print(df_media_desvpad_fa_rand['AUCs modelo estatístico'].mean())\n",
    "ax = df_media_desvpad_fa_rand[['AUCs modelo estatístico', 'AUCs SVM', 'AUCs XGBoost']].plot(figsize=(16,10))\n",
    "\n",
    "\n",
    "# valid_markers = mpl.markers.MarkerStyle.filled_markers\n",
    "markers = np.random.choice(valid_markers, df_media_desvpad_fa_rand.shape[1], replace=False)\n",
    "for i, line in enumerate(ax.get_lines()):\n",
    "    line.set_marker(markers[i])\n",
    "\n",
    "plt.title('AUCs nas execuções até convergência')\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "\n",
    "plt.savefig('auc_pso_bigml.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise da avaliação de, os rótulos classificados pelo XGBoost, serem um subconjunto da classificação de rótulos do SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto = pd.DataFrame(data = np.round(predictionsSVM)[:,1], columns = ['SVM'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Target'] = y_test_svm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['XGBoost'] = np.round(predictionsXGBoost[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_SVM'] = df_analise_subconjunto['SVM'][(df_analise_subconjunto['SVM'] == df_analise_subconjunto['Target'])].replace(to_replace = 0, value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_SVM'] = np.nan_to_num(df_analise_subconjunto['Acertos_SVM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_SVM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_XGBoost'] = df_analise_subconjunto['XGBoost'][(np.logical_and(df_analise_subconjunto['XGBoost'],1) & np.logical_and(df_analise_subconjunto['Target'],1))].replace(to_replace = 0, value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_XGBoost'] = np.nan_to_num(df_analise_subconjunto['Acertos_XGBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte(x):\n",
    "    if x == True:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Iguais_ambos'] = df_analise_subconjunto['Acertos_SVM'] == df_analise_subconjunto['Acertos_XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_SVM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_XGBoost'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Iguais_ambos'] = df_analise_subconjunto['Iguais_ambos'].apply(converte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Iguais_ambos'] = df_analise_subconjunto[df_analise_subconjunto['Iguais_ambos'] == df_analise_subconjunto['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Iguais_ambos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_SVM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_XGBoost'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico dos valores de Alpha e Beta para o ponderamento do modelo estatístico bayesiano com o PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_media_desvpad_PSO_rand['solucao_x'] = np.clip(df_media_desvpad_PSO_rand['solucao_x'], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_media_desvpad_PSO_rand['solucao_y'] = np.clip(df_media_desvpad_PSO_rand['solucao_y'], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand['solucao_x'].rename('alpha', inplace=True)\n",
    "df_media_desvpad_PSO_rand['solucao_y'].rename('beta', inplace=True)\n",
    "\n",
    "df_media_desvpad_PSO_rand.rename(columns={'solucao_x':'alpha',\n",
    "                          'solucao_y':'beta'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand[['alpha', 'beta']].plot(figsize=(12,6))\n",
    "plt.title(\"Valores de alpha e beta para as execuções do PSO\")\n",
    "plt.savefig('alpha_beta_pso.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand['alpha'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand['beta'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Parâmetros XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFoldRand(x_pca_svm, df_bigml_target, np.random.randint(0,10000))\n",
    "X_train_xgboost, X_test_xgboost, y_train_xgboost, y_test_xgboost = aplicaKFoldRand(x_pca_xgboost, df_bigml_target, np.random.randint(0,10000))\n",
    "#gb1 = XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8,\n",
    "#                       colsample_bytree=0.8, objective= 'binary:logistic', nthread=4)\n",
    " \n",
    "gb1 = XGBClassifier(objective= 'binary:logistic', nthread=4)\n",
    " \n",
    "grid_values = {'n_estimators': np.arange(1, 200, 20),'colsample_bytree':np.arange(0.5, 1.1, 0.1), 'max_depth': np.arange(3, 20), 'learning_rate': np.arange(0.01, 0.21, 0.01)}\n",
    "grid_gb1_acc = GridSearchCV(gb1, param_grid = grid_values,scoring = 'roc_auc', verbose = 2)\n",
    "grid_gb1_acc.fit(X_train_xgboost, y_train_xgboost)\n",
    "\n",
    "#Predict values based on new parameters\n",
    "y_pred_acc = grid_gb1_acc.predict_proba(X_test_xgboost)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_xgboost, y_pred_acc[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "\n",
    "# New Model Evaluation metrics \n",
    "print('AUC Score : ' + str(roc_auc))\n",
    "print(grid_gb1_acc.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação do XGBoost com parametrização atualizada junto ao modelo estatístico e PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaXGBoostOtimizado(X_train, X_test, y_train):\n",
    "    xg_reg = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.9, learning_rate = 1,\n",
    "                max_depth = 11, alpha = 10, n_estimators = 60)\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    predictionsXGBoost = xg_reg.predict_proba(X_test)\n",
    "    return predictionsXGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SwarmPackagePy\n",
    "import matplotlib.pyplot as plt\n",
    "from SwarmPackagePy import testFunctions as tf\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "df_bigml, df_bigml_target = descarregaBaseDados()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_bigml)\n",
    "\n",
    "tempo_rand = []\n",
    "melhor_rand = []\n",
    "rands = []\n",
    "auc_fa = []\n",
    "auc_svm = []\n",
    "auc_xgboost = []\n",
    "convergencia = False\n",
    "media_aucs = 0\n",
    "auc_anterior = 0\n",
    "total_iguais = 0\n",
    "i = 0\n",
    "while(not convergencia):\n",
    "    print(i)\n",
    "    rand = np.random.randint(0, 1000)\n",
    "    t1_start = perf_counter()  \n",
    "    scaled_data = scaler.transform(df_bigml)  \n",
    "    pca_svm = PCA(n_components = 16)\n",
    "    pca_svm.fit(scaled_data)\n",
    "    x_pca_svm = pca_svm.transform(scaled_data)\n",
    "\n",
    "    pca_xgboost = PCA(n_components=17)\n",
    "    pca_xgboost.fit(scaled_data)\n",
    "    x_pca_xgboost = pca_xgboost.transform(scaled_data)\n",
    "    rands.append(rand)\n",
    "    X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFoldRand(x_pca_svm, df_bigml_target, rand)\n",
    "    X_train_xgboost, X_test_xgboost, y_train_xgboost, y_test_xgboost = aplicaKFoldRand(x_pca_xgboost, df_bigml_target, rand)\n",
    "    \n",
    "    predictionsSVM = aplicaSVM(X_train_svm, X_test_svm, y_train_svm)\n",
    "    predictionsXGBoost = aplicaXGBoostOtimizado(X_train_xgboost, X_test_xgboost, y_train_xgboost)\n",
    "    \n",
    "    fprs, tprs, thresholdss = roc_curve(y_test_svm, predictionsSVM[:,1])\n",
    "    fprx, tprx, thresholdsx = roc_curve(y_test_svm, predictionsXGBoost[:,1])\n",
    "    \n",
    "    auc_svm.append(auc(fprs, tprs))\n",
    "    auc_xgboost.append(auc(fprx, tprx))\n",
    "    \n",
    "    vetor_pbest = []\n",
    "    vetor_acertos = []\n",
    "    \n",
    "    alh = pso(40, retorna_acertos, 0, 1, 2, 50, y_test_svm, vetor_pbest, vetor_acertos)\n",
    "    solucao = alh.get_Gbest()\n",
    "    svm_alpha = ( ( 1 - predictionsSVM[:,1] ) ** solucao[0] )\n",
    "    xgboost_beta =  ( ( 1 - predictionsXGBoost[:,1] ) ** solucao[1])\n",
    "    predicoes = 1 - (svm_alpha*xgboost_beta)\n",
    "    qtd_acertos = np.subtract(y_test_svm,np.round(predicoes))\n",
    "    np.count_nonzero(qtd_acertos == 0)/len(y_test_svm) * 100\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_svm, predicoes)\n",
    "    auc_fa.append(auc(fpr, tpr))\n",
    "    \n",
    "    media_aucs = round(sum(auc_fa)/len(auc_fa), 2)\n",
    "    if media_aucs == auc_anterior:\n",
    "        total_iguais = total_iguais + 1\n",
    "    else:\n",
    "        total_iguais = 0\n",
    "    \n",
    "    if total_iguais == 10:\n",
    "        convergencia = True\n",
    "    \n",
    "    print('media_aucs:{}'.format(media_aucs))\n",
    "    auc_anterior = media_aucs\n",
    "    \n",
    "    arr = np.array(alh.get_agents())\n",
    "    t1_stop = perf_counter() \n",
    "    melhor_rand.append(alh.get_Gbest())\n",
    "    tempo_rand.append(t1_stop-t1_start)\n",
    "    \n",
    "    print(alh.get_Gbest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand = pd.DataFrame()\n",
    "df_media_desvpad_PSO_rand['tempo'] = tempo_rand\n",
    "df_media_desvpad_PSO_rand['solucoes'] = melhor_rand\n",
    "df_media_desvpad_PSO_rand['rand_values'] = rands\n",
    "df_media_desvpad_PSO_rand['aucs'] = auc_fa\n",
    "df_media_desvpad_PSO_rand['auc_svm'] = auc_svm\n",
    "df_media_desvpad_PSO_rand['auc_xgboost'] = auc_xgboost\n",
    "df_media_desvpad_PSO_rand[['solucao_x','solucao_y']] = pd.DataFrame(df_media_desvpad_PSO_rand.solucoes.values.tolist(), index= df_media_desvpad_PSO_rand.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico das AUCs nas execuções "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# create valid markers from mpl.markers\n",
    "valid_markers = ([item[0] for item in mpl.markers.MarkerStyle.markers.items() if\n",
    "item[1] is not 'nothing' and not item[1].startswith('tick') and not item[1].startswith('caret')])\n",
    "df_media_desvpad_PSO_rand.rename(columns = {'aucs':'AUCs modelo estatístico', 'auc_svm':'AUCs SVM', 'auc_xgboost' : 'AUCs XGBoost'}, inplace = True) \n",
    "\n",
    "print(df_media_desvpad_PSO_rand['AUCs modelo estatístico'].std())\n",
    "ax = df_media_desvpad_PSO_rand[['AUCs modelo estatístico', 'AUCs SVM', 'AUCs XGBoost']].plot(figsize=(16,10))\n",
    "\n",
    "\n",
    "# valid_markers = mpl.markers.MarkerStyle.filled_markers\n",
    "markers = np.random.choice(valid_markers, df_media_desvpad_PSO_rand.shape[1], replace=False)\n",
    "for i, line in enumerate(ax.get_lines()):\n",
    "    line.set_marker(markers[i])\n",
    "\n",
    "plt.title('AUCs nas execuções até convergência com otimização do XGBoost')\n",
    "plt.rcParams.update({'font.size': 21})\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "\n",
    "plt.savefig('auc_pso_bigml_otimizacao_xgboost.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alh = pso(40, retorna_acertos, 0, 1, 2, 50, y_test_svm, vetor_pbest, vetor_acertos)\n",
    "animationFA(alh.get_agents(), retorna_acertos, 0, 1, y_test_svm, sr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(auc_xgboost)/len(auc_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
