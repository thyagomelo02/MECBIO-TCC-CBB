{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCC CBB\n",
    "\n",
    "Desenvolvido por Ricardo e Thyago.\n",
    "\n",
    "#### Objetivo: \n",
    "\n",
    "Aplicação das técnicas de classificação SVM e XGboost junto ao algoritmo bio-inspirado PSO.\n",
    "\n",
    "Neste script é aplicado os algoritmos de classificação SVM e XGboost também o modelo estatístico\n",
    "com seu ponderamento feito pelos algoritmos Bio-inspirados.\n",
    "Também é calculado a Média, tempo e desvio-padrão, bem como o Tempo de execução e a Distância euclidiana \n",
    "entre a posição dos melhores agentes para o PSO.\n",
    "\n",
    "Fez-se a analise dos parâmetros de aplicação do XGBoost e a técnica foi reaplicada com os paramêtros atualizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import bigml.api\n",
    "import os\n",
    "import pandas as pd\n",
    "from bigml.api import BigML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import plotly.express as px\n",
    "import cufflinks as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\Users\\\\Ricardo\\\\Desktop\\\\ffmpeg-20200206-343ccfc-win64-static\\\\bin\\\\ffmpeg.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import das bibliotecas do XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = BigML('ricardomorellosantos','b34ec3c18161b1da38b0c5e04520224f7544405e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.download_dataset(dataset='dataset/5e356cd41efc9271bf006ea2', filename=os.getcwd()+'\\\\bigml.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de tratamento da base de dados Churn in Telecom's data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_binario(palavra):\n",
    "    if palavra=='Yes' or palavra==True:\n",
    "        return 0\n",
    "    elif palavra=='No' or palavra==False:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descarregaBaseDados():\n",
    "    df_bigml = pd.read_csv(os.getcwd()+'\\\\bigml.csv')\n",
    "    states = df_bigml['State'].value_counts()\n",
    "    df_bigml['Voice mail plan'] = df_bigml['Voice mail plan'].apply(converte_binario)\n",
    "    df_bigml['International plan'] = df_bigml['International plan'].apply(converte_binario)\n",
    "    df_bigml['Churn'] = df_bigml['Churn'].apply(converte_binario)\n",
    "    df_bigml_target = df_bigml['Churn']\n",
    "    df_bigml.drop('Churn', axis=1, inplace=True)\n",
    "    df_bigml_target.head()\n",
    "    print(df_bigml_target.value_counts())\n",
    "    array_estados = []\n",
    "    i = 0\n",
    "    for index, val in states.iteritems():\n",
    "        array_estados.append(index)    \n",
    "        i = 0\n",
    "    for estado in array_estados:\n",
    "        df_bigml['State'] = df_bigml['State'].replace(to_replace=estado, value=i)\n",
    "        i = i+1\n",
    "    return df_bigml, df_bigml_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para Kfold, XGBoost e SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaKFold(x_pca, df_bigml_target):\n",
    "    divisao = 0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_pca, df_bigml_target, test_size=divisao, random_state = 42)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaSVM(X_train, X_test, y_train): \n",
    "    modelSVM = SVC(probability=True, kernel = 'rbf')\n",
    "    modelSVM.fit(X_train, y_train)\n",
    "    predictionsSVM = modelSVM.predict_proba(X_test)\n",
    "\n",
    "    return predictionsSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaXGBoost(X_train, X_test, y_train):\n",
    "    xg_reg = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 10)\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    predictionsXGBoost = xg_reg.predict_proba(X_test)\n",
    "    return predictionsXGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicações do algoritmo bio-inspirado PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class swa(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.__Positions = []\n",
    "        self.__Gbest = []\n",
    "\n",
    "    def _set_Gbest(self, __Gbest):\n",
    "        self.__Gbest = __Gbest\n",
    "\n",
    "    def _points(self, agents):\n",
    "        self.__Positions.append([list(i) for i in agents])\n",
    "\n",
    "    def get_agents(self):\n",
    "        \"\"\"Returns a history of all agents of the algorithm (return type:\n",
    "        list)\"\"\"\n",
    "\n",
    "        return self.__Positions\n",
    "\n",
    "    def get_Gbest(self):\n",
    "        \"\"\"Return the best position of algorithm (return type: list)\"\"\"\n",
    "\n",
    "        return list(self.__Gbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class pso(swa):\n",
    "    \"\"\"\n",
    "    Particle Swarm Optimization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, function, lb, ub, dimension, iteration, y_test_svm,vetor_pbest, vetor_acertos, w=0.5, c1=1,\n",
    "                 c2=1):\n",
    "        \"\"\"\n",
    "        :param n: number of agents\n",
    "        :param function: test function\n",
    "        :param lb: lower limits for plot axes\n",
    "        :param ub: upper limits for plot azes\n",
    "        :param dimension: space dimension\n",
    "        :param iteration: the number of iterations\n",
    "        :param w: balance between the range of research and consideration for\n",
    "        suboptimal decisions found (default value is 0.5):\n",
    "        w>1 the particle velocity increases, they fly apart and inspect\n",
    "         the space more carefully;\n",
    "        w<1 particle velocity decreases, convergence speed depends\n",
    "        on parameters c1 and c2 ;\n",
    "        :param c1: ratio between \"cognitive\" and \"social\" component\n",
    "        (default value is 1)\n",
    "        :param c2: ratio between \"cognitive\" and \"social\" component\n",
    "        (default value is 1)\n",
    "        \"\"\"\n",
    "\n",
    "        super(pso, self).__init__()\n",
    "\n",
    "        self.__agents = trunca_agentes(np.random.uniform(lb, ub, (n, dimension)))\n",
    "        velocity = np.zeros((n, dimension))\n",
    "        self._points(self.__agents)\n",
    "\n",
    "        Pbest = self.__agents[np.array([function(x, y_test_svm)\n",
    "                                        for x in self.__agents]).argmax()]\n",
    "        Gbest = Pbest\n",
    "        vetor_pbest.append(Pbest)\n",
    "        vetor_acertos.append(function(Pbest, y_test_svm))\n",
    "        \n",
    "        for t in range(iteration):\n",
    "            r1 = np.random.random((n, dimension))\n",
    "            r2 = np.random.random((n, dimension))\n",
    "            velocity = w * velocity + c1 * r1 * (\n",
    "                Pbest - self.__agents) + c2 * r2 * (\n",
    "                Gbest - self.__agents)\n",
    "            self.__agents += velocity\n",
    "            self.__agents = trunca_agentes(np.clip(self.__agents, lb, ub))\n",
    "            self._points(self.__agents)\n",
    "         \n",
    "            Pbest = self.__agents[\n",
    "                np.array([function(x, y_test_svm) for x in self.__agents]).argmax()]\n",
    "            if function(Pbest, y_test_svm) > function(Gbest, y_test_svm):\n",
    "                Gbest = Pbest\n",
    "            vetor_pbest.append(Pbest)\n",
    "            vetor_acertos.append(function(Pbest, y_test_svm))\n",
    "        \n",
    "        self._set_Gbest(Gbest)\n",
    "        print(Gbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação dos algoritmos XGBoost e SVM junto ao algoritmos PSO até sua convergência "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SwarmPackagePy\n",
    "import matplotlib.pyplot as plt\n",
    "from SwarmPackagePy import testFunctions as tf\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "df_bigml, df_bigml_target = descarregaBaseDados()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_bigml)\n",
    "\n",
    "tempo_rand = []\n",
    "melhor_rand = []\n",
    "rands = []\n",
    "auc_fa = []\n",
    "auc_svm = []\n",
    "auc_xgboost = []\n",
    "convergencia = False\n",
    "media_aucs = 0\n",
    "auc_anterior = 0\n",
    "total_iguais = 0\n",
    "i = 0\n",
    "while(not convergencia):\n",
    "    print(i)\n",
    "    rand = np.random.randint(0, 1000)\n",
    "    t1_start = perf_counter()  \n",
    "    scaled_data = scaler.transform(df_bigml)  \n",
    "    pca_svm = PCA(n_components = 16)\n",
    "    pca_svm.fit(scaled_data)\n",
    "    x_pca_svm = pca_svm.transform(scaled_data)\n",
    "\n",
    "    pca_xgboost = PCA(n_components=17)\n",
    "    pca_xgboost.fit(scaled_data)\n",
    "    x_pca_xgboost = pca_xgboost.transform(scaled_data)\n",
    "    rands.append(rand)\n",
    "    X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFoldRand(x_pca_svm, df_bigml_target, rand)\n",
    "    X_train_xgboost, X_test_xgboost, y_train_xgboost, y_test_xgboost = aplicaKFoldRand(x_pca_xgboost, df_bigml_target, rand)\n",
    "    \n",
    "    predictionsSVM = aplicaSVM(X_train_svm, X_test_svm, y_train_svm)\n",
    "    predictionsXGBoost = aplicaXGBoost(X_train_xgboost, X_test_xgboost, y_train_xgboost)\n",
    "    \n",
    "    fprs, tprs, thresholdss = roc_curve(y_test_svm, predictionsSVM[:,1])\n",
    "    fprx, tprx, thresholdsx = roc_curve(y_test_svm, predictionsXGBoost[:,1])\n",
    "    \n",
    "    auc_svm.append(auc(fprs, tprs))\n",
    "    auc_xgboost.append(auc(fprx, tprx))\n",
    "    \n",
    "    vetor_pbest = []\n",
    "    vetor_acertos = []\n",
    "\n",
    "    alh = pso(40, retorna_acertos, 0, 1, 2, 50, y_test_svm, vetor_pbest, vetor_acertos)\n",
    "    solucao = alh.get_Gbest()\n",
    "    svm_alpha = ( ( 1 - predictionsSVM[:,1] ) ** solucao[0] )\n",
    "    xgboost_beta =  ( ( 1 - predictionsXGBoost[:,1] ) ** solucao[1])\n",
    "    predicoes = 1 - (svm_alpha*xgboost_beta)\n",
    "    qtd_acertos = np.subtract(y_test_svm,np.round(predicoes))\n",
    "    np.count_nonzero(qtd_acertos == 0)/len(y_test_svm) * 100\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_svm, predicoes)\n",
    "    auc_fa.append(auc(fpr, tpr))\n",
    "    \n",
    "    media_aucs = round(sum(auc_fa)/len(auc_fa), 2)\n",
    "    if media_aucs == auc_anterior:\n",
    "        total_iguais = total_iguais + 1\n",
    "    else:\n",
    "        total_iguais = 0\n",
    "    \n",
    "    if total_iguais == 10:\n",
    "        convergencia = True\n",
    "    \n",
    "    print('media_aucs:{}'.format(media_aucs))\n",
    "    auc_anterior = media_aucs\n",
    "    \n",
    "    arr = np.array(alh.get_agents())\n",
    "    t1_stop = perf_counter() \n",
    "    melhor_rand.append(alh.get_Gbest())\n",
    "    tempo_rand.append(t1_stop-t1_start)\n",
    "    \n",
    "    print(alh.get_Gbest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Média, desvio padrão para o PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand = pd.DataFrame()\n",
    "df_media_desvpad_PSO_rand['tempo'] = tempo_rand\n",
    "df_media_desvpad_PSO_rand['solucoes'] = melhor_rand\n",
    "df_media_desvpad_PSO_rand['rand_values'] = rands\n",
    "df_media_desvpad_PSO_rand['aucs'] = auc_fa\n",
    "df_media_desvpad_PSO_rand['auc_svm'] = auc_svm\n",
    "df_media_desvpad_PSO_rand['auc_xgboost'] = auc_xgboost\n",
    "df_media_desvpad_PSO_rand[['solucao_x','solucao_y']] = pd.DataFrame(df_media_desvpad_PSO_rand.solucoes.values.tolist(), index= df_media_desvpad_PSO_rand.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico do tempo de execução do PSO até sua convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_media_desvpad_PSO_rand['tempo'].std())\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.title('Tempo de execução até convergência da média')\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('Tempo (s)')\n",
    "df_media_desvpad_PSO_rand['tempo'].plot(yerr=df_media_desvpad_PSO_rand['tempo'].std(), marker = 'o')\n",
    "plt.savefig('tempo_execucao_pso_bigml.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da distância euclidiana dos melhores agentes para o PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "distancias_euclidianas = []\n",
    "cont = 0\n",
    "for i in df_media_desvpad_fa_rand['solucoes']:\n",
    "    if cont < len(df_media_desvpad_fa_rand['solucoes']) - 1:\n",
    "        proximo = df_media_desvpad_fa_rand['solucoes'][cont+1]\n",
    "        primeiro_ponto = (i[0], i[1])\n",
    "        segundo_ponto = (proximo[0], proximo[1])\n",
    "        distancias_euclidianas.append(distance.euclidean(primeiro_ponto, segundo_ponto))\n",
    "        cont = cont+1\n",
    "    else:\n",
    "        distancias_euclidianas.append(0)\n",
    "df_media_desvpad_fa_rand['distancias_euclidianas'] = distancias_euclidianas\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.title('Distância euclidiana entre os melhores agentes até convergência da média')\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('Distância euclidiana')\n",
    "df_media_desvpad_fa_rand['distancias_euclidianas'] = np.clip(df_media_desvpad_fa_rand['distancias_euclidianas'],0, 1)\n",
    "df_media_desvpad_fa_rand['distancias_euclidianas'].plot(yerr=df_media_desvpad_fa_rand['distancias_euclidianas'].std(), marker = 'o', color='red')\n",
    "plt.savefig('distancia_euclidiana_pso_bigml.png')\n",
    "\n",
    "print(df_media_desvpad_fa_rand['distancias_euclidianas'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico das AUCs em cada execução do PSO até sua convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# create valid markers from mpl.markers\n",
    "valid_markers = ([item[0] for item in mpl.markers.MarkerStyle.markers.items() if\n",
    "item[1] is not 'nothing' and not item[1].startswith('tick') and not item[1].startswith('caret')])\n",
    "df_media_desvpad_fa_rand.rename(columns = {'aucs':'AUCs modelo estatístico', 'auc_svm':'AUCs SVM', 'auc_xgboost' : 'AUCs XGBoost'}, inplace = True) \n",
    "\n",
    "print(df_media_desvpad_PSO_rand['AUCs modelo estatístico'].mean())\n",
    "ax = df_media_desvpad_PSO_rand[['AUCs modelo estatístico', 'AUCs SVM', 'AUCs XGBoost']].plot(figsize=(16,10))\n",
    "\n",
    "\n",
    "# valid_markers = mpl.markers.MarkerStyle.filled_markers\n",
    "markers = np.random.choice(valid_markers, df_media_desvpad_PSO_rand.shape[1], replace=False)\n",
    "for i, line in enumerate(ax.get_lines()):\n",
    "    line.set_marker(markers[i])\n",
    "\n",
    "plt.title('AUCs nas execuções até convergência')\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "\n",
    "plt.savefig('auc_pso_bigml.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise da avaliação de, os rótulos classificados pelo XGBoost, serem um subconjunto da classificação de rótulos do SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto = pd.DataFrame(data = np.round(predictionsSVM)[:,1], columns = ['SVM'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Target'] = y_test_svm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['XGBoost'] = np.round(predictionsXGBoost[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_SVM'] = df_analise_subconjunto['SVM'][(df_analise_subconjunto['SVM'] == df_analise_subconjunto['Target'])].replace(to_replace = 0, value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_SVM'] = np.nan_to_num(df_analise_subconjunto['Acertos_SVM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_SVM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_XGBoost'] = df_analise_subconjunto['XGBoost'][(np.logical_and(df_analise_subconjunto['XGBoost'],1) & np.logical_and(df_analise_subconjunto['Target'],1))].replace(to_replace = 0, value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_XGBoost'] = np.nan_to_num(df_analise_subconjunto['Acertos_XGBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte(x):\n",
    "    if x == True:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Iguais_ambos'] = df_analise_subconjunto['Acertos_SVM'] == df_analise_subconjunto['Acertos_XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_SVM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_XGBoost'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Iguais_ambos'] = df_analise_subconjunto['Iguais_ambos'].apply(converte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Iguais_ambos'] = df_analise_subconjunto[df_analise_subconjunto['Iguais_ambos'] == df_analise_subconjunto['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Iguais_ambos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_SVM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_subconjunto['Acertos_XGBoost'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico dos valores de Alpha e Beta para o ponderamento do modelo estatístico bayesiano com o PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_media_desvpad_PSO_rand['solucao_x'] = np.clip(df_media_desvpad_PSO_rand['solucao_x'], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_media_desvpad_PSO_rand['solucao_y'] = np.clip(df_media_desvpad_PSO_rand['solucao_y'], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand['solucao_x'].rename('alpha', inplace=True)\n",
    "df_media_desvpad_PSO_rand['solucao_y'].rename('beta', inplace=True)\n",
    "\n",
    "df_media_desvpad_PSO_rand.rename(columns={'solucao_x':'alpha',\n",
    "                          'solucao_y':'beta'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand[['alpha', 'beta']].plot(figsize=(12,6))\n",
    "plt.title(\"Valores de alpha e beta para as execuções do PSO\")\n",
    "plt.savefig('alpha_beta_pso.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand['alpha'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand['beta'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Parâmetros XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFoldRand(x_pca_svm, df_bigml_target, np.random.randint(0,10000))\n",
    "X_train_xgboost, X_test_xgboost, y_train_xgboost, y_test_xgboost = aplicaKFoldRand(x_pca_xgboost, df_bigml_target, np.random.randint(0,10000))\n",
    "#gb1 = XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8,\n",
    "#                       colsample_bytree=0.8, objective= 'binary:logistic', nthread=4)\n",
    " \n",
    "gb1 = XGBClassifier(objective= 'binary:logistic', nthread=4)\n",
    " \n",
    "grid_values = {'n_estimators': np.arange(1, 200, 20),'colsample_bytree':np.arange(0.5, 1.1, 0.1), 'max_depth': np.arange(3, 20), 'learning_rate': np.arange(0.01, 0.21, 0.01)}\n",
    "grid_gb1_acc = GridSearchCV(gb1, param_grid = grid_values,scoring = 'roc_auc', verbose = 2)\n",
    "grid_gb1_acc.fit(X_train_xgboost, y_train_xgboost)\n",
    "\n",
    "#Predict values based on new parameters\n",
    "y_pred_acc = grid_gb1_acc.predict_proba(X_test_xgboost)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_xgboost, y_pred_acc[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "\n",
    "# New Model Evaluation metrics \n",
    "print('AUC Score : ' + str(roc_auc))\n",
    "print(grid_gb1_acc.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação do XGBoost com parametrização atualizada junto ao modelo estatístico e PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaXGBoostOtimizado(X_train, X_test, y_train):\n",
    "    xg_reg = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.9, learning_rate = 1,\n",
    "                max_depth = 11, alpha = 10, n_estimators = 60)\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    predictionsXGBoost = xg_reg.predict_proba(X_test)\n",
    "    return predictionsXGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SwarmPackagePy\n",
    "import matplotlib.pyplot as plt\n",
    "from SwarmPackagePy import testFunctions as tf\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "df_bigml, df_bigml_target = descarregaBaseDados()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_bigml)\n",
    "\n",
    "tempo_rand = []\n",
    "melhor_rand = []\n",
    "rands = []\n",
    "auc_fa = []\n",
    "auc_svm = []\n",
    "auc_xgboost = []\n",
    "convergencia = False\n",
    "media_aucs = 0\n",
    "auc_anterior = 0\n",
    "total_iguais = 0\n",
    "i = 0\n",
    "while(not convergencia):\n",
    "    print(i)\n",
    "    rand = np.random.randint(0, 1000)\n",
    "    t1_start = perf_counter()  \n",
    "    scaled_data = scaler.transform(df_bigml)  \n",
    "    pca_svm = PCA(n_components = 16)\n",
    "    pca_svm.fit(scaled_data)\n",
    "    x_pca_svm = pca_svm.transform(scaled_data)\n",
    "\n",
    "    pca_xgboost = PCA(n_components=17)\n",
    "    pca_xgboost.fit(scaled_data)\n",
    "    x_pca_xgboost = pca_xgboost.transform(scaled_data)\n",
    "    rands.append(rand)\n",
    "    X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFoldRand(x_pca_svm, df_bigml_target, rand)\n",
    "    X_train_xgboost, X_test_xgboost, y_train_xgboost, y_test_xgboost = aplicaKFoldRand(x_pca_xgboost, df_bigml_target, rand)\n",
    "    \n",
    "    predictionsSVM = aplicaSVM(X_train_svm, X_test_svm, y_train_svm)\n",
    "    predictionsXGBoost = aplicaXGBoostOtimizado(X_train_xgboost, X_test_xgboost, y_train_xgboost)\n",
    "    \n",
    "    fprs, tprs, thresholdss = roc_curve(y_test_svm, predictionsSVM[:,1])\n",
    "    fprx, tprx, thresholdsx = roc_curve(y_test_svm, predictionsXGBoost[:,1])\n",
    "    \n",
    "    auc_svm.append(auc(fprs, tprs))\n",
    "    auc_xgboost.append(auc(fprx, tprx))\n",
    "    \n",
    "    vetor_pbest = []\n",
    "    vetor_acertos = []\n",
    "    \n",
    "    alh = pso(40, retorna_acertos, 0, 1, 2, 50, y_test_svm, vetor_pbest, vetor_acertos)\n",
    "    solucao = alh.get_Gbest()\n",
    "    svm_alpha = ( ( 1 - predictionsSVM[:,1] ) ** solucao[0] )\n",
    "    xgboost_beta =  ( ( 1 - predictionsXGBoost[:,1] ) ** solucao[1])\n",
    "    predicoes = 1 - (svm_alpha*xgboost_beta)\n",
    "    qtd_acertos = np.subtract(y_test_svm,np.round(predicoes))\n",
    "    np.count_nonzero(qtd_acertos == 0)/len(y_test_svm) * 100\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_svm, predicoes)\n",
    "    auc_fa.append(auc(fpr, tpr))\n",
    "    \n",
    "    media_aucs = round(sum(auc_fa)/len(auc_fa), 2)\n",
    "    if media_aucs == auc_anterior:\n",
    "        total_iguais = total_iguais + 1\n",
    "    else:\n",
    "        total_iguais = 0\n",
    "    \n",
    "    if total_iguais == 10:\n",
    "        convergencia = True\n",
    "    \n",
    "    print('media_aucs:{}'.format(media_aucs))\n",
    "    auc_anterior = media_aucs\n",
    "    \n",
    "    arr = np.array(alh.get_agents())\n",
    "    t1_stop = perf_counter() \n",
    "    melhor_rand.append(alh.get_Gbest())\n",
    "    tempo_rand.append(t1_stop-t1_start)\n",
    "    \n",
    "    print(alh.get_Gbest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand = pd.DataFrame()\n",
    "df_media_desvpad_PSO_rand['tempo'] = tempo_rand\n",
    "df_media_desvpad_PSO_rand['solucoes'] = melhor_rand\n",
    "df_media_desvpad_PSO_rand['rand_values'] = rands\n",
    "df_media_desvpad_PSO_rand['aucs'] = auc_fa\n",
    "df_media_desvpad_PSO_rand['auc_svm'] = auc_svm\n",
    "df_media_desvpad_PSO_rand['auc_xgboost'] = auc_xgboost\n",
    "df_media_desvpad_PSO_rand[['solucao_x','solucao_y']] = pd.DataFrame(df_media_desvpad_PSO_rand.solucoes.values.tolist(), index= df_media_desvpad_PSO_rand.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico das AUCs nas execuções "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# create valid markers from mpl.markers\n",
    "valid_markers = ([item[0] for item in mpl.markers.MarkerStyle.markers.items() if\n",
    "item[1] is not 'nothing' and not item[1].startswith('tick') and not item[1].startswith('caret')])\n",
    "df_media_desvpad_PSO_rand.rename(columns = {'aucs':'AUCs modelo estatístico', 'auc_svm':'AUCs SVM', 'auc_xgboost' : 'AUCs XGBoost'}, inplace = True) \n",
    "\n",
    "print(df_media_desvpad_PSO_rand['AUCs modelo estatístico'].std())\n",
    "ax = df_media_desvpad_PSO_rand[['AUCs modelo estatístico', 'AUCs SVM', 'AUCs XGBoost']].plot(figsize=(16,10))\n",
    "\n",
    "\n",
    "# valid_markers = mpl.markers.MarkerStyle.filled_markers\n",
    "markers = np.random.choice(valid_markers, df_media_desvpad_PSO_rand.shape[1], replace=False)\n",
    "for i, line in enumerate(ax.get_lines()):\n",
    "    line.set_marker(markers[i])\n",
    "\n",
    "plt.title('AUCs nas execuções até convergência com otimização do XGBoost')\n",
    "plt.rcParams.update({'font.size': 21})\n",
    "plt.xlabel('Execução')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "\n",
    "plt.savefig('auc_pso_bigml_otimizacao_xgboost.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alh = pso(40, retorna_acertos, 0, 1, 2, 50, y_test_svm, vetor_pbest, vetor_acertos)\n",
    "animationFA(alh.get_agents(), retorna_acertos, 0, 1, y_test_svm, sr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(auc_xgboost)/len(auc_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_desvpad_PSO_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
