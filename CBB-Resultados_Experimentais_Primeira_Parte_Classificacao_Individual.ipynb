{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCC-CBB \n",
    "\n",
    "Objetivo: Testar aplicação dos algoritmos PCA, SVM e XGBoost em Python\n",
    "\n",
    "Data: 31/01/2020\n",
    "\n",
    "Desenvolvido por: Thyago e Ricardo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script tem por objetivo visualizar resultados da aplicação dos algoritmos SVM e XGBoost na base de dados BigML. O primeiro passo consiste em instalar as bibliotecas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bigml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas BigML (API para download do dataset), OS (para verificar o caminho que se está executando o python) e Pandas (para criação dos dataframes, estrutura de dados utilizada nos algoritmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigml.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigml.api import BigML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura da base de dados\n",
    "Utilização das credenciais para leitura do dataset por meio da API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = BigML('ricardomorellosantos','b34ec3c18161b1da38b0c5e04520224f7544405e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura do dataset e gravando-o no diretório atual em um arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.download_dataset(dataset='dataset/5e356cd41efc9271bf006ea2', filename=os.getcwd()+'\\\\bigml.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura do dataset em uma estrutura de dados DataFrame do pandas. Um dataframe é uma estrutura que permite armazenar dados heterogêneos de maneira tabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigml = pd.read_csv(os.getcwd()+'\\\\bigml.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apresentando informações sobre a base de dados já armazenada em um dataframe.\n",
    "\n",
    "Primeiros 5 registros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bigml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informações sobre colunas e número de registros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos dados para utilização do algoritmo PCA\n",
    "Dados do tipo string serão convertidos para números para aplicação do PCA.\n",
    "Colunas que possuem valores binários (Yes e No ou True e False) serão alteradas para Yes = 0, True = 0, No = 1 e False = 1, transformando estes valores em números.\n",
    "\n",
    "Função para, dada uma palavra (Yes ou No, True ou False), retornar um valor booleano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_binario(palavra):\n",
    "    if palavra=='Yes' or palavra==True:\n",
    "        return 0\n",
    "    elif palavra=='No' or palavra==False:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando essa função nas colunas Voice Mail Plan e International Plan (que contém valores Yes e No) e Churn (que contém True ou False). A coluna Churn é o target do dataframe. A coluna target é aquela que contém a resposta da classificação. Neste caso, se o usuário deixou ou manteve o plano com a operadora de telefonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigml['Voice mail plan'] = df_bigml['Voice mail plan'].apply(converte_binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigml['International plan'] = df_bigml['International plan'].apply(converte_binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigml['Churn'] = df_bigml['Churn'].apply(converte_binario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apreentando as primeiras 5 linhas do novo dataframe, para verificar se a transformação foi feita da maneira correta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_bigml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna Churn é o target desta classificação. Portanto, ela será armazenada em um dataframe a parte, para que ela não interfira no algoritmo PCA e para realizar a separação do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigml_target = df_bigml['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluindo a coluna Churn do dataframe original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigml.drop('Churn', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizando os 5 primeiros registros do novo dataframe que contém apenas o resultado da classificação, df_bigml_target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigml_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataframe antigo contém agora apenas as colunas não-target, visto que a coluna Churn foi excluída e copiada para outro dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_bigml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas linhas apenas foram executadas para verificar a proporção de Yes e No nas colunas após a transformação destes valores para 0 e 1. Nota-se que os valores 1 (No) e 0 (Yes) contém os mesmos números de registros de antes da transformação. Portanto, a função foi aplicada corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigml['Voice mail plan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = df_bigml['State'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, os dados de estados serão transformados em números para aplicação do PCA. Cada estado será armazenado em um vetor, e seu correspondente na coluna do dataframe assumirá o valor do índice deste vetor. Por exemplo, no vetor de estados v = ['KS', 'CA', 'WV', 'OH'], o estado da Califórnia assume o índice 1. Desta maneira, na coluna do dataframe, seu novo valor será substituído de Ca para 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_estados = []\n",
    "i = 0\n",
    "for index, val in states.iteritems():\n",
    "    array_estados.append(index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for estado in array_estados:\n",
    "    df_bigml['State'] = df_bigml['State'].replace(to_replace=estado, value=i)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização dos dados para aplicação do PCA\n",
    "\n",
    "Utilizamos um normalizador para manter os dados na mesma escala, evitando que diferenças em escalas nos dados interfiram negativamente no PCA. Importando a classe do normalizador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciando a classe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando o normalizador com o dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(df_bigml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando os dados do dataframe para o mesmo espaço numérico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scaler.transform(df_bigml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação do PCA\n",
    "Então, aplicou-se o PCA com 3 componentes. Importando a classe do PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciando a classe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando o PCA com os dados. Nota-se que, agora, não estamos utilizando o dataframe original df_bigml, e sim o dataframe com os dados normalizados, denominado scaled_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz que conterá os dados após a aplicação do pca:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca = pca.transform(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizando as novas dimensões:\n",
    "\n",
    "A matriz x_pca, que contém os dados após aplicação do PCA, possui apenas três colunas, referentes aos três componentes principais. Por outro lado, o dataframe scaled_data possui 19 dimensões, referentes às dimensões originais do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optamos por visualizar os dados do PCA num gráfico 3D interativo. Isto permite ver a distribuição espacial dos dados. \n",
    "Importando as bibliotecas para visualização 3D dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import cufflinks as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas configurações da biblioteca plotly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs,init_notebook_mode,plot,iplot\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um dataframe com o vetor de saída dos dados do PCA. Este dataframe será utilizado apenas para visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(data=x_pca, columns = ['PC1','PC2','PC3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurando e apresentando o gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df_pca, x='PC1', y='PC2', z='PC3',\n",
    "                    color=df_bigml_target)\n",
    "                    \n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Gráfico de dispersão PCA\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"#7f7f7f\"\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão da base de dados em treino e teste\n",
    "\n",
    "Para dividir a base de dados, optamos pelo fator 0.30. Importando a biblioteca para separação do dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividindo o dataframe em treino e teste. X_train e X_test contém os dados dos componentes, enquanto y_train e y_test contém os resultados da classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, df_bigml_target, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação do SVM\n",
    "\n",
    "Importando a biblioteca do SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciando uma classe do SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(probability=True, gamma = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando o SVM à divisão de treino: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando a predição do SVM na divisão de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicoes_svm = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do SVM\n",
    "\n",
    "Utilizaremo as bibliotecas classification_report e confusion_matrix para apresentar as métricas da avaliação da classificação do SVM. Importando as bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apresentação dos resultados da classificação do SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predicoes_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, predicoes_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação do XGBoost\n",
    "Importando as bibliotecas do XGBoost. Esta biblioteca não é padrão do Python, e deve ser instalada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciando o classificador XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10, probability = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando o classificador e realizando a predição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do XGBoost\n",
    "Apresentação dos resultados para o algoritmo XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Média e desvio padrão do SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_anterior = 0\n",
    "auc_svm = []\n",
    "medias_svm = []\n",
    "convergencia = False\n",
    "qtd_iguais = 0\n",
    "pca = PCA(n_components = 16)\n",
    "pca.fit(scaled_data)\n",
    "x_pca = pca.transform(scaled_data)\n",
    "while(not convergencia):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_pca, df_bigml_target, test_size=0.20)\n",
    "    model.fit(X_train,y_train)\n",
    "    predictedprob = model.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predictedprob[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_svm.append(roc_auc)\n",
    "    media_aucs = round(sum(auc_svm) / len(auc_svm), 2) \n",
    "    medias_svm.append(media_aucs)\n",
    "    print(media_aucs)\n",
    "    if media_anterior == media_aucs:\n",
    "        qtd_iguais = qtd_iguais + 1\n",
    "    else:\n",
    "        qtd_iguais = 0\n",
    "    if qtd_iguais == 10:\n",
    "        convergencia = True\n",
    "    media_anterior = media_aucs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "data_svm = pd.DataFrame({'AUC':auc_svm, 'Média AUCs':medias_svm})\n",
    "ax = data_svm.plot(title = 'AUC X Iteração SVM', figsize = (12, 6))\n",
    "ax.text(4.5, 0.84, 'Desvio padrão:{}'.format(round(statistics.stdev(medias_svm), 4)))\n",
    "plt.savefig('auc_iteracao_svm_bigml.PNG')\n",
    "print(sorted(auc_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Média e desvio padrão do XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_anterior = 0\n",
    "auc_xgboost = []\n",
    "medias_xgboost = []\n",
    "convergencia = False\n",
    "qtd_iguais = 0\n",
    "pca = PCA(n_components = 17)\n",
    "pca.fit(scaled_data)\n",
    "x_pca = pca.transform(scaled_data)\n",
    "while(not convergencia):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_pca, df_bigml_target, test_size=0.10)\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    predictedprob = xg_reg.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predictedprob[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_xgboost.append(roc_auc)\n",
    "    media_aucs = round(sum(auc_xgboost) / len(auc_xgboost), 2) \n",
    "    medias_xgboost.append(media_aucs)\n",
    "    print(roc_auc)\n",
    "    if media_anterior == media_aucs:\n",
    "        qtd_iguais = qtd_iguais + 1\n",
    "    else:\n",
    "        qtd_iguais = 0\n",
    "    if qtd_iguais >= 10:\n",
    "        convergencia = True\n",
    "    media_anterior = media_aucs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "data_xgboost = pd.DataFrame({'AUC':auc_xgboost, 'Média AUCs':medias_xgboost})\n",
    "ax = data_xgboost.plot(title = 'AUC X Iteração XGBoost', figsize = (12, 6))\n",
    "ax.text(11, 0.7, 'Desvio padrão:{}'.format(round(statistics.stdev(medias_xgboost), 4)))\n",
    "plt.savefig('auc_iteracao_xgboost_bigml.PNG')\n",
    "print(medias_xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gráfico de média e desvio padrão xgboost e svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc_med_desvpad = pd.DataFrame(auc_med_desvpad_xgboost)\n",
    "print(len(auc_med_desvpad_xgboost))\n",
    "print(len(auc_med_desvpad_svm))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "g = sns.lineplot(data = df_auc_med_desvpad_svm, marker = 'o', )\n",
    "g.legend('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc_med_desvpad['SVM'] = auc_med_desvpad_svm\n",
    "df_auc_med_desvpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curva ROC SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "pca.fit(scaled_data)\n",
    "x_pca = pca.transform(scaled_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, df_bigml_target, test_size=0.30)\n",
    "model.fit(X_train,y_train)\n",
    "predictedprobSVC = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictedprobSVC[:,1])\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAPH DATA\n",
    "fig = plt.figure()\n",
    "plt.xlabel('1-Especificidade')\n",
    "plt.ylabel('Sensibilidade')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.title('Curva ROC SVM')\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='SVM ROC area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "fig.savefig('ROC_svm.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curva ROC XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1,20):\n",
    "pca = PCA(n_components = 16)\n",
    "pca.fit(scaled_data)\n",
    "x_pca = pca.transform(scaled_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, df_bigml_target, test_size=0.20)\n",
    "model.fit(X_train,y_train)\n",
    "predictedprob = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictedprob[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAPH DATA\n",
    "fig = plt.figure()\n",
    "plt.xlabel('1-Especificidade')\n",
    "plt.ylabel('Sensibilidade')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.title('Curva ROC SVM')\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='SVM ROC area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "fig.savefig('ROC_SVM_otimizado.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do PCA e divisão teste/treino - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_total = []\n",
    "auc_divisao = []\n",
    "convergencia = False\n",
    "\n",
    "numAucsComponente = []\n",
    "numAucsDivisao = []\n",
    "for divisao in np.arange(0.1, 1, 0.1):\n",
    "    print(divisao)\n",
    "    for numComponentes in range(1,20):\n",
    "        print(numComponentes)\n",
    "        auc_componente = []\n",
    "        media_anterior = 0\n",
    "        qtd_iguais = 0\n",
    "        pca = PCA(n_components = numComponentes)\n",
    "        pca.fit(scaled_data)\n",
    "        x_pca = pca.transform(scaled_data)\n",
    "        convergencia = False\n",
    "        while(not convergencia):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x_pca, df_bigml_target, test_size=divisao)\n",
    "            model.fit(X_train,y_train)\n",
    "            predictedprob = model.predict_proba(X_test)\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, predictedprob[:,1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            auc_componente.append(roc_auc)\n",
    "            media_aucs = round(sum(auc_componente) / len(auc_componente), 2) \n",
    "            #print(media_aucs)\n",
    "            if media_anterior == media_aucs:\n",
    "                qtd_iguais = qtd_iguais + 1\n",
    "            else:\n",
    "                qtd_iguais = 0\n",
    "            if qtd_iguais >= 10:\n",
    "                numAucsComponente.append(len(auc_componente))\n",
    "                auc_total.append(media_aucs)\n",
    "                convergencia = True\n",
    "            media_anterior = media_aucs\n",
    "    numAucsDivisao.append(numAucsComponente)\n",
    "    numAucsComponente = []\n",
    "    auc_divisao.append(auc_total)\n",
    "    auc_total = []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de assertividade com base no número de componentes do SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x):\n",
    "    return x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "\n",
    "df_divisao = pd.DataFrame(auc_divisao)\n",
    "df_divisao.set_index(np.arange(1,10), inplace = True)\n",
    "df_divisao.rename(add, axis='columns', inplace=True)\n",
    "sns.heatmap(data = df_divisao)\n",
    "plt.title(\"Assertividade SVM\")\n",
    "plt.savefig('assertividade-svm-divisao-numcomponentes.PNG')\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de mapa de calor do SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "\n",
    "df = pd.DataFrame(numAucsDivisao)\n",
    "df.set_index(np.arange(1,10), inplace = True)\n",
    "df.rename(add, axis='columns', inplace=True)\n",
    "sns.heatmap(data = df, cmap = 'YlGnBu')\n",
    "plt.title(\"Quantidade de iterações até a convergência SVM\")\n",
    "plt.savefig('iteracoes-svm-divisao-numcomponentes.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do PCA e divisão teste/treino - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_total = []\n",
    "auc_divisao = []\n",
    "convergencia = False\n",
    "\n",
    "numAucsComponente = []\n",
    "numAucsDivisao = []\n",
    "for divisao in np.arange(0.1, 1, 0.1):\n",
    "    print(divisao)\n",
    "    for numComponentes in range(1,20):\n",
    "        print(numComponentes)\n",
    "        auc_componente = []\n",
    "        media_anterior = 0\n",
    "        qtd_iguais = 0\n",
    "        pca = PCA(n_components = numComponentes)\n",
    "        pca.fit(scaled_data)\n",
    "        x_pca = pca.transform(scaled_data)\n",
    "        convergencia = False\n",
    "        while(not convergencia):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x_pca, df_bigml_target, test_size=divisao)\n",
    "            xg_reg.fit(X_train,y_train)\n",
    "            predictedprob = xg_reg.predict_proba(X_test)\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, predictedprob[:,1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            auc_componente.append(roc_auc)\n",
    "            media_aucs = round(sum(auc_componente) / len(auc_componente), 2) \n",
    "            print(len(auc_componente))\n",
    "            if media_anterior == media_aucs:\n",
    "                qtd_iguais = qtd_iguais + 1\n",
    "            else:\n",
    "                qtd_iguais = 0\n",
    "            if qtd_iguais >= 20:\n",
    "                numAucsComponente.append(len(auc_componente))\n",
    "                auc_total.append(media_aucs)\n",
    "                print(len(auc_componente))\n",
    "                convergencia = True\n",
    "            media_anterior = media_aucs\n",
    "    numAucsDivisao.append(numAucsComponente)\n",
    "    numAucsComponente = []\n",
    "    auc_divisao.append(auc_total)\n",
    "    auc_total = []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de assertividade com base no número de componentes do XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "\n",
    "df_divisao = pd.DataFrame(auc_divisao)\n",
    "df_divisao.set_index(np.arange(1,10), inplace = True)\n",
    "df_divisao.rename(add, axis='columns', inplace=True)\n",
    "sns.heatmap(data = df_divisao)\n",
    "plt.title(\"Assertividade XGBoost\")\n",
    "plt.savefig('assertividade-xgboost-divisao-numcomponentes.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de mapa de calor para o XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "\n",
    "df = pd.DataFrame(numAucsDivisao)\n",
    "df.set_index(np.arange(1,10), inplace = True)\n",
    "df.rename(add, axis='columns', inplace=True)\n",
    "sns.heatmap(data = df, cmap = 'YlGnBu')\n",
    "plt.title(\"Quantidade de iterações até a convergência XGBoost\")\n",
    "plt.savefig('iteracoes-xgboost-divisao-numcomponentes.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
