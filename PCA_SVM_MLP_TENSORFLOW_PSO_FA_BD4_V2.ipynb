{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCC CBB\n",
    "\n",
    "Desenvolvido por Ricardo e Thyago.\n",
    "\n",
    "#### Objetivo: \n",
    "\n",
    "Aplicação das técnicas de classificação SVM, MLP e Tensorflow junto ao algoritmo bio-inspirado PSO e aplicado na base de dados de doenças cardiovasculares.\n",
    "\n",
    "Neste script é aplicado os algoritmos de classificação SVM, MLP e Tensorflow e o modelo estatístico\n",
    "com seu ponderamento feito pelos algoritmos Bio-inspirados.\n",
    "\n",
    "Fez-se a analise dos parâmetros de aplicação do XGBoost e a técnica foi reaplicada com os paramêtros atualizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APLICAÇÃO COM A BASE DE DADOS CUSTUMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import bigml.api\n",
    "import os\n",
    "import pandas as pd\n",
    "from bigml.api import BigML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection, metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaSVM(X_train, X_test, y_train): \n",
    "    \n",
    "    model_svm = SVC(probability = True, kernel = 'rbf', gamma = 'scale')\n",
    "    model_svm.fit(X_train, y_train)\n",
    "    predictionsSVM = model_svm.predict_proba(X_test)\n",
    "    \n",
    "    return predictionsSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import do KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "#tensorflow.keras.models\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaTensor(X_train, X_test, y_train, y_test, dim_input):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(40, input_dim=dim_input, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=100)\n",
    "    \n",
    "    predictionsTensor = model.predict_proba(X_test)\n",
    "\n",
    "    return predictionsTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\Users\\\\Thyago M\\\\Desktop\\\\ffmpeg.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import do MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, model_selection, metrics\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaMLP(X_train, X_test, y_train):\n",
    "    #X_train, X_test, y_train, y_test = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "   \n",
    "    modelMLP = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    modelMLP.fit(X_train, y_train)\n",
    "    predictionsMLP = modelMLP.predict_proba(X_test)\n",
    "    \n",
    "    return predictionsMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASE DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_binario(palavra):\n",
    "    if palavra=='Yes' or palavra==True:\n",
    "        return 0\n",
    "    elif palavra=='No' or palavra==False:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descarregaBaseCardio():    \n",
    "    df_cardio = pd.read_csv(os.getcwd()+'\\\\cardio_train.csv',sep=\";\")\n",
    "    df_cardio_target = df_cardio['cardio']\n",
    "    df_cardio.drop('cardio', axis=1, inplace=True)\n",
    "    df_cardio.drop('id', axis=1, inplace=True)\n",
    "    \n",
    "    return df_cardio, df_cardio_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APLICA K-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaKFold(x_pca, df_weather_target):\n",
    "    divisao = 0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_pca, df_weather_target, test_size=divisao)\n",
    "   \n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_acertos(predicoes, y_test):\n",
    "    qtd_acertos = []\n",
    "    for i in range(predicoes.shape[0]):\n",
    "        if predicoes[i] == y_test[i]:\n",
    "            qtd_acertos.append(1)\n",
    "        else:\n",
    "            qtd_acertos.append(0)\n",
    "    return np.asarray(qtd_acertos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicaKFoldVariado(x_pca, df_cardio_target,divisao):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_pca, df_cardio_target, test_size=divisao)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bio Inspirados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sw(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.__Positions = []\n",
    "        self.__Gbest = []\n",
    "\n",
    "    def _set_Gbest(self, Gbest):\n",
    "        self.__Gbest = Gbest\n",
    "\n",
    "    def _points(self, agents):\n",
    "        self.__Positions.append([list(i) for i in agents])\n",
    "\n",
    "    def get_agents(self):\n",
    "        \"\"\"Returns a history of all agents of the algorithm (return type:\n",
    "        list)\"\"\"\n",
    "\n",
    "        return self.__Positions\n",
    "\n",
    "    def get_Gbest(self):\n",
    "        \"\"\"Return the best position of algorithm (return type: list)\"\"\"\n",
    "\n",
    "        return list(self.__Gbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "class fa(sw):\n",
    "    \"\"\"\n",
    "    Firefly Algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, n, function, lb, ub, dimension, iteration, y_test, vetor_pbest, vetor_acertos, csi=1, psi=1,\n",
    "                 alpha0=10, alpha1=0.5, norm0=0, norm1=0.1):\n",
    "        \"\"\"\n",
    "        :param n: number of agents\n",
    "        :param function: test function\n",
    "        :param lb: lower limits for plot axes\n",
    "        :param ub: upper limits for plot axes\n",
    "        :param dimension: space dimension\n",
    "        :param iteration: number of iterations\n",
    "        :param csi: mutual attraction (default value is 1)\n",
    "        :param psi: light absorption coefficient of the medium\n",
    "        (default value is 1)\n",
    "        :param alpha0: initial value of the free randomization parameter alpha\n",
    "        (default value is 1)\n",
    "        :param alpha1: final value of the free randomization parameter alpha\n",
    "        (default value is 0.1)\n",
    "        :param norm0: first parameter for a normal (Gaussian) distribution\n",
    "        (default value is 0)\n",
    "        :param norm1: second parameter for a normal (Gaussian) distribution\n",
    "        (default value is 0.1)\n",
    "        \"\"\"\n",
    "\n",
    "        super(fa, self).__init__()\n",
    "\n",
    "        self.__agents = np.random.uniform(lb, ub, (n, dimension))\n",
    "        self._points(self.__agents)\n",
    "        Pbest = self.__agents[np.array([function(x, y_test)\n",
    "                                        for x in self.__agents]).argmax()]\n",
    "        Gbest = Pbest\n",
    "        vetor_pbest.append(Pbest)\n",
    "        vetor_acertos.append(function(Pbest, y_test))\n",
    "        for t in range(iteration):\n",
    "            alpha = alpha1 + (alpha0 - alpha1) * exp(-t)\n",
    "            for i in range(n):\n",
    "                fitness = [function(x, y_test) for x in self.__agents]\n",
    "                for j in range(n):\n",
    "                    if fitness[i] < fitness[j]:\n",
    "                        self.__move(i, j, t, csi, psi, alpha, dimension,\n",
    "                                    norm0, norm1)\n",
    "                    else:\n",
    "                        self.__agents[i] += np.random.normal(norm0, norm1,\n",
    "                                                             dimension)\n",
    "\n",
    "            self.__agents = np.clip(self.__agents, lb, ub)\n",
    "            self._points(self.__agents)\n",
    "            \n",
    "            Pbest = self.__agents[\n",
    "                np.array([function(x, y_test) for x in self.__agents]).argmax()]\n",
    "            if function(Pbest, y_test) > function(Gbest, y_test):\n",
    "                Gbest = Pbest\n",
    "            vetor_pbest.append(Gbest)\n",
    "            vetor_acertos.append(function(Gbest, y_test))\n",
    "        self._set_Gbest(Gbest)\n",
    "\n",
    "    def __move(self, i, j, t, csi, psi, alpha, dimension, norm0, norm1):\n",
    "        r = np.linalg.norm(self.__agents[i] - self.__agents[j])\n",
    "        beta = csi / (1 + psi * r ** 2)\n",
    "        self.__agents[i] = self.__agents[j] + beta * (\n",
    "            self.__agents[i] - self.__agents[j]) + alpha * exp(-t) * \\\n",
    "                                                   np.random.normal(norm0,\n",
    "                                                                    norm1,\n",
    "                                                                    dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class swa(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.__Positions = []\n",
    "        self.__Gbest = []\n",
    "\n",
    "    def _set_Gbest(self, __Gbest):\n",
    "        self.__Gbest = __Gbest\n",
    "\n",
    "    def _points(self, agents):\n",
    "        self.__Positions.append([list(i) for i in agents])\n",
    "\n",
    "    def get_agents(self):\n",
    "        \"\"\"Returns a history of all agents of the algorithm (return type:\n",
    "        list)\"\"\"\n",
    "\n",
    "        return self.__Positions\n",
    "\n",
    "    def get_Gbest(self):\n",
    "        \"\"\"Return the best position of algorithm (return type: list)\"\"\"\n",
    "\n",
    "        return list(self.__Gbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class pso(swa):\n",
    "    \"\"\"\n",
    "    Particle Swarm Optimization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, function, lb, ub, dimension, iteration, y_test_svm, vetor_pbest, vetor_acertos, w=0.5, c1=1,\n",
    "                 c2=1):\n",
    "        \"\"\"\n",
    "        :param n: number of agents\n",
    "        :param function: test function\n",
    "        :param lb: lower limits for plot axes\n",
    "        :param ub: upper limits for plot azes\n",
    "        :param dimension: space dimension\n",
    "        :param iteration: the number of iterations\n",
    "        :param w: balance between the range of research and consideration for\n",
    "        suboptimal decisions found (default value is 0.5):\n",
    "        w>1 the particle velocity increases, they fly apart and inspect\n",
    "         the space more carefully;\n",
    "        w<1 particle velocity decreases, convergence speed depends\n",
    "        on parameters c1 and c2 ;\n",
    "        :param c1: ratio between \"cognitive\" and \"social\" component\n",
    "        (default value is 1)\n",
    "        :param c2: ratio between \"cognitive\" and \"social\" component\n",
    "        (default value is 1)\n",
    "        \"\"\"\n",
    "\n",
    "        super(pso, self).__init__()\n",
    "\n",
    "        self.__agents = np.random.uniform(lb, ub, (n, dimension))\n",
    "        velocity = np.zeros((n, dimension))\n",
    "        self._points(self.__agents)\n",
    "\n",
    "        Pbest = self.__agents[np.array([function(x, y_test_svm)\n",
    "                                        for x in self.__agents]).argmax()]\n",
    "        Gbest = Pbest\n",
    "        vetor_pbest.append(Pbest)\n",
    "        vetor_acertos.append(function(Pbest, y_test_svm))\n",
    "        \n",
    "        for t in range(iteration):\n",
    "            r1 = np.random.random((n, dimension))\n",
    "            r2 = np.random.random((n, dimension))\n",
    "            velocity = w * velocity + c1 * r1 * (\n",
    "                Pbest - self.__agents) + c2 * r2 * (\n",
    "                Gbest - self.__agents)\n",
    "            self.__agents += velocity\n",
    "            self.__agents = np.clip(self.__agents, lb, ub)\n",
    "            self._points(self.__agents)\n",
    "         \n",
    "            Pbest = self.__agents[\n",
    "                np.array([function(x, y_test_svm) for x in self.__agents]).argmax()]\n",
    "            if function(Pbest, y_test_svm) > function(Gbest, y_test_svm):\n",
    "                Gbest = Pbest\n",
    "            vetor_pbest.append(Pbest)\n",
    "            vetor_acertos.append(function(Pbest, y_test_svm))\n",
    "        \n",
    "        self._set_Gbest(Gbest)\n",
    "        print(Gbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicações FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SwarmPackagePy\n",
    "import matplotlib.pyplot as plt\n",
    "#from SwarmPackagePy import testFunctions as tf\n",
    "\n",
    "df_cardio, df_cardio_target = descarregaBaseCardio()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "random = np.random.randint(1,1000)\n",
    "scaler.fit(df_cardio)\n",
    "\n",
    "scaled_data = scaler.transform(df_cardio)  \n",
    "\n",
    "pca_svm = PCA(n_components = 11)\n",
    "pca_svm.fit(scaled_data)\n",
    "x_pca_svm = pca_svm.transform(scaled_data)\n",
    "\n",
    "pca_tensorflow = PCA(n_components=9)\n",
    "pca_tensorflow.fit(scaled_data)\n",
    "x_pca_tensorflow = pca_tensorflow.transform(scaled_data)\n",
    "\n",
    "pca_MLP = PCA(n_components = 6)\n",
    "pca_MLP.fit(scaled_data)\n",
    "x_pca_mlp = pca_MLP.transform(scaled_data)\n",
    "\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFold2(x_pca_svm, df_cardio_target, 0.1, random)\n",
    "X_train_tensorflow, X_test_tensorflow, y_train_tensorflow, y_test_tensorflow = aplicaKFold2(x_pca_tensorflow, df_cardio_target, 0.1, random)\n",
    "X_train_mlp, X_test_mlp, y_train_mlp, y_test_mlp = aplicaKFold2(x_pca_mlp, df_cardio_target, 0.1, random)\n",
    "\n",
    "predictionsSVM = aplicaSVM(X_train_svm, X_test_svm, y_train_svm)\n",
    "predictionsTensorflow = aplicaTensor(X_train_tensorflow, X_test_tensorflow, y_train_tensorflow, y_test_tensorflow, 9)\n",
    "predictionsMLP = aplicaMLP(X_train_mlp, X_test_mlp, y_train_mlp)\n",
    "\n",
    "predictionsTensorflowAjustado = []\n",
    "\n",
    "for row in predictionsTensorflow:\n",
    "    predictionsTensorflowAjustado.append(row[0])\n",
    "predictionsTensorflowAjustado = np.asarray(predictionsTensorflowAjustado)\n",
    "\n",
    "vetor_pbest = []\n",
    "vetor_acertos = []\n",
    "\n",
    "alh = fa(40, retorna_acertos, 0, 1, 2, 20, y_test_svm)\n",
    "#alh1 = pso(40, retorna_acertos, 0, 1, 3, 20,  y_test_tensorflow, vetor_pbest,vetor_acertos )\n",
    "arr1 = np.array(alh.get_agents())\n",
    "animationFA(alh.get_agents(), retorna_acertos, 0, 1, y_test_svm, sr=True)\n",
    "animation3D(alh.get_agents(), retorna_acertos, 0, 1, y_test_svm, sr=True)\n",
    "print(alh.get_Gbest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APlicação do Modelo estatístico para o FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_alpha = ( ( 1 - predictionsSVM[:,1]) ** alh.get_Gbest()[0] )\n",
    "tensorflow_beta =  ( ( 1 - predictionsTensorflowAjustado) ** alh.get_Gbest()[1])\n",
    "mlp_gamma = ( ( 1 - predictionsMLP[:,1] ) ** alh.get_Gbest()[2])\n",
    "predicoes = 1 - (svm_alpha*tensorflow_beta*mlp_gamma)\n",
    "qtd_acertos = np.subtract(y_test_svm,np.round(predicoes))\n",
    "np.count_nonzero(qtd_acertos == 0)/len(y_test_svm) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APlicação PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SwarmPackagePy\n",
    "import matplotlib.pyplot as plt\n",
    "#from SwarmPackagePy import testFunctions as tf\n",
    "\n",
    "df_bigml, df_bigml_target = descarregaBaseCardio()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "random = np.random.randint(1,1000)\n",
    "scaler.fit(df_cardio)\n",
    "\n",
    "scaled_data = scaler.transform(df_cardio)  \n",
    "\n",
    "pca_svm = PCA(n_components = 11)\n",
    "pca_svm.fit(scaled_data)\n",
    "x_pca_svm = pca_svm.transform(scaled_data)\n",
    "\n",
    "pca_tensorflow = PCA(n_components=9)\n",
    "pca_tensorflow.fit(scaled_data)\n",
    "x_pca_tensorflow = pca_tensorflow.transform(scaled_data)\n",
    "#predictionsTensorflow = aplicaTensor(X_train_tensorflow, X_test_tensorflow, y_train_tensorflow, 17)\n",
    "\n",
    "pca_MLP = PCA(n_components = 11)\n",
    "pca_MLP.fit(scaled_data)\n",
    "x_pca_mlp = pca_MLP.transform(scaled_data)\n",
    "\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = aplicaKFold2(x_pca_svm, df_cardio_target, 0.1, random)\n",
    "X_train_tensorflow, X_test_tensorflow, y_train_tensorflow, y_test_tensorflow = aplicaKFold2(x_pca_tensorflow, df_cardio_target, 0.1, random)\n",
    "X_train_mlp, X_test_mlp, y_train_mlp, y_test_mlp = aplicaKFold2(x_pca_mlp, df_cardio_target, 0.1, random)\n",
    "\n",
    "predictionsSVM = aplicaSVM(X_train_svm, X_test_svm, y_train_svm)\n",
    "predictionsTensorflow = aplicaTensor(X_train_tensorflow, X_test_tensorflow, y_train_tensorflow, y_test_tensorflow, 9)\n",
    "predictionsMLP = aplicaMLP(X_train_mlp, X_test_mlp, y_train_mlp)\n",
    "\n",
    "predictionsTensorflowAjustado = []\n",
    "\n",
    "for row in predictionsTensorflow:\n",
    "    predictionsTensorflowAjustado.append(row[0])\n",
    "predictionsTensorflowAjustado = np.asarray(predictionsTensorflowAjustado)\n",
    "\n",
    "vetor_pbest = []\n",
    "vetor_acertos = []\n",
    "\n",
    "#alh = fa(40, retorna_acertos, 0, 1, 2, 20, y_test_svm)\n",
    "alh1 = pso(40, retorna_acertos, 0, 1, 3, 20,  y_test_tensorflow, vetor_pbest,vetor_acertos )\n",
    "arr1 = np.array(alh1.get_agents())\n",
    "animationFA(alh1.get_agents(), retorna_acertos, 0, 1, y_test_svm, sr=True)\n",
    "animation3D(alh1.get_agents(), retorna_acertos, 0, 1, y_test_svm, sr=True)\n",
    "print(alh1.get_Gbest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação do Modelo estatístico para o PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_alpha = ( ( 1 - predictionsSVM[:,1]) ** alh1.get_Gbest()[0] )\n",
    "tensorflow_beta =  ( ( 1 - predictionsTensorflowAjustado) ** alh1.get_Gbest()[1])\n",
    "mlp_gamma = ( ( 1 - predictionsMLP[:,1] ) ** alh1.get_Gbest()[2])\n",
    "predicoes = 1 - (svm_alpha*tensorflow_beta*mlp_gamma)\n",
    "qtd_acertos = np.subtract(y_test_svm,np.round(predicoes))\n",
    "np.count_nonzero(qtd_acertos == 0)/len(y_test_svm) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
